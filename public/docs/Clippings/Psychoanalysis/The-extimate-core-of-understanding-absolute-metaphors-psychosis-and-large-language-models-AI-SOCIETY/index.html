<!doctype html><html lang=en dir=ltr><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1314&amp;path=livereload" data-no-instant defer></script><script>(function(){const e=localStorage.getItem("theme");e&&document.documentElement.setAttribute("data-theme",e)})()</script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This paper delves into the striking parallels between the linguistic patterns of Large Language Models (LLMs) and the concepts of psychosis in Lacanian psy"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="http://localhost:1314/docs/Clippings/Psychoanalysis/The-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models-AI-SOCIETY/"><meta property="og:site_name" content="学习笔记"><meta property="og:title" content="The extimate core of understanding: absolute metaphors, psychosis and large language models - AI & SOCIETY"><meta property="og:description" content="This paper delves into the striking parallels between the linguistic patterns of Large Language Models (LLMs) and the concepts of psychosis in Lacanian psy"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2024-05-17T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-17T00:00:00+00:00"><meta property="article:tag" content="Clippings"><meta property="article:tag" content="Psychoanalysis"><title>The extimate core of understanding: absolute metaphors, psychosis and large language models - AI & SOCIETY | 学习笔记</title>
<link rel=icon href=/topo.png><link rel=manifest href=/manifest.json><link rel=canonical href=http://localhost:1314/docs/Clippings/Psychoanalysis/The-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models-AI-SOCIETY/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/computer-modern-font@1.0.1/index.min.css><link rel=stylesheet href=/book.min.9817edb59c26d9512efc69286fe27f6cb3404844da8e2478d3fea7373c9fa336.css integrity="sha256-mBfttZwm2VEu/Gkob+J/bLNASETajiR40/6nNzyfozY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.02146d62883b84f93e0524565edbcf1e9c978da904f495247ceef863dda858c9.js integrity="sha256-AhRtYog7hPk+BSRWXtvPHpyXjakE9JUkfO74Y92oWMk=" crossorigin=anonymous></script><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class=container><div class=book-layout><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center justify-center" href=http://localhost:1314/><span>学习笔记</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><nav class=subject-menu><div class=subject-tabs><button class="subject-tab active" data-subject=数学>数学</button>
<button class=subject-tab data-subject=物理>物理</button></div><div class=subject-content><div class=subject-panel data-subject=数学></div><div class="subject-panel hidden" data-subject=物理></div></div></nav><script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".subject-tab"),s=document.querySelectorAll(".subject-panel");function t(t){e.forEach(e=>e.classList.remove("active")),s.forEach(e=>e.classList.add("hidden"));const n=document.querySelector(`.subject-tab[data-subject="${t}"]`);n&&n.classList.add("active");const o=document.querySelector(`.subject-panel[data-subject="${t}"]`);o&&o.classList.remove("hidden"),localStorage.setItem("activeSubjectTab",t)}const n=localStorage.getItem("activeSubjectTab");n&&t(n),e.forEach(e=>{e.addEventListener("click",function(){const n=e.getAttribute("data-subject");t(n)})})})</script><div class=after-menu-offset><ul><li><a href=/posts/>Blog</a></li><li><a href=https://github.com/EriseHe/notebook target=_blank rel=noopener>Github</a></li><li><a href=https://themes.gohugo.io/themes/hugo-book/ target=_blank rel=noopener>Hugo Themes</a></li></ul></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>The extimate core of understanding: absolute metaphors, psychosis and large language models - AI & SOCIETY</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#the-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models>The extimate core of understanding: absolute metaphors, psychosis and large language models</a></li><li><a href=#abstract>Abstract</a><ul><li><a href=#similar-content-being-viewed-by-others>Similar content being viewed by others</a></li><li><a href=#from-large-language-models-to-small-logic-programs-building-global-explanations-from-disagreeing-local-post-hoc-explainers>From large language models to small logic programs: building global explanations from disagreeing local post-hoc explainers</a></li><li><a href=#large-language-models-could-change-the-future-of-behavioral-healthcare-a-proposal-for-responsible-development-and-evaluation>Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation</a></li><li><a href=#testing-ai-on-language-comprehension-tasks-reveals-insensitivity-to-underlying-meaning>Testing AI on language comprehension tasks reveals insensitivity to underlying meaning</a></li></ul></li><li><a href=#1-introduction>1 Introduction</a></li><li><a href=#2-metaphor-and-metonymy>2 Metaphor and metonymy</a><ul><li><a href=#21-metaphors-and-the-user>2.1 Metaphors and the user</a></li></ul></li><li><a href=#3-metaphors-and-the-void>3 Metaphors and the void</a></li><li><a href=#4-foreclosure-in-llms>4 Foreclosure in LLMs</a></li><li><a href=#5-coda>5 Coda</a></li><li><a href=#data-availability>Data availability</a></li><li><a href=#notes>Notes</a></li><li><a href=#references>References</a></li><li><a href=#funding>Funding</a></li><li><a href=#author-information>Author information</a><ul><li><a href=#authors-and-affiliations>Authors and Affiliations</a></li><li><a href=#contributions>Contributions</a></li><li><a href=#corresponding-author>Corresponding author</a></li></ul></li><li><a href=#ethics-declarations>Ethics declarations</a><ul><li><a href=#conflict-of-interest>Conflict of interest</a></li><li><a href=#human-rights>Human rights</a></li></ul></li><li><a href=#additional-information>Additional information</a><ul><li><a href=#publishers-note>Publisher&rsquo;s Note</a></li></ul></li><li><a href=#rights-and-permissions>Rights and permissions</a></li><li><a href=#about-this-article>About this article</a><ul><li><a href=#cite-this-article>Cite this article</a></li><li><a href=#share-this-article>Share this article</a></li><li><a href=#keywords>Keywords</a></li><li><a href=#profiles>Profiles</a></li></ul></li></ul></li></ul></nav></aside></header><article class=book-article><h1 style="text-align:center;font-family:computer modern,cmu serif,serif">The extimate core of understanding: absolute metaphors, psychosis and large language models - AI & SOCIETY</h1><div class="markdown posts" x-data><p data-raw=Advertisement>Advertisement</p><h2 id=the-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models>The extimate core of understanding: absolute metaphors, psychosis and large language models
<a class=anchor href=#the-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models>#</a></h2><ul><li>Main Paper</li><li><a href=https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research>Open access</a></li><li>Published:</li><li>Volume 40, pages 1265–1276, (2025)</li><li><a href="https://link.springer.com/article/10.1007/?utm_source=chatgpt.com#citeas">Cite this article</a></li></ul><p data-raw='You have full access to this 
  <a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research">open access</a> article'>You have full access to this
<a href=https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research>open access</a> article</p><p data-raw='
  <a href="https://link.springer.com/journal/146">
  <img src="https://media.springernature.com/w72/springer-static/cover-hires/journal/146?as=webp" alt="" /> AI & SOCIETY</a> 
  <a href="https://link.springer.com/journal/146/aims-and-scope">Aims and scope</a> 
  <a href="https://submission.springernature.com/new-submission/146/3">Submit manuscript</a>'><a href=https://link.springer.com/journal/146><img src="https://media.springernature.com/w72/springer-static/cover-hires/journal/146?as=webp" alt> AI & SOCIETY</a>
<a href=https://link.springer.com/journal/146/aims-and-scope>Aims and scope</a>
<a href=https://submission.springernature.com/new-submission/146/3>Submit manuscript</a></p><h2 id=abstract>Abstract
<a class=anchor href=#abstract>#</a></h2><p data-raw='This paper delves into the striking parallels between the linguistic patterns of Large Language Models (LLMs) and the concepts of psychosis in Lacanian psychoanalysis. Lacanian theory, with its focus on the formal and logical underpinnings of psychosis, provides a compelling lens to juxtapose human cognition and AI mechanisms. LLMs, such as GPT-4, appear to replicate the intricate metaphorical and metonymical frameworks inherent in human language. Although grounded in mathematical logic and probabilistic analysis, the outputs of LLMs echo the nuanced linguistic associations found in metaphor and metonymy, suggesting a mirroring of human linguistic structures. A pivotal point in this discourse is the exploration of “absolute metaphors”—core gaps in reasoning discernible in both AI models and human thought processes and central to the Lacanian conceptualization of psychosis. Despite the traditional divide between AI research and continental philosophy, this analysis embarks on an innovative journey, utilizing Lacanian philosophy to unravel the logic of AI, using concepts established in the continental discourse on logic, rather than the analytical tradition.'>This paper delves into the striking parallels between the linguistic patterns of Large Language Models (LLMs) and the concepts of psychosis in Lacanian psychoanalysis. Lacanian theory, with its focus on the formal and logical underpinnings of psychosis, provides a compelling lens to juxtapose human cognition and AI mechanisms. LLMs, such as GPT-4, appear to replicate the intricate metaphorical and metonymical frameworks inherent in human language. Although grounded in mathematical logic and probabilistic analysis, the outputs of LLMs echo the nuanced linguistic associations found in metaphor and metonymy, suggesting a mirroring of human linguistic structures. A pivotal point in this discourse is the exploration of “absolute metaphors”—core gaps in reasoning discernible in both AI models and human thought processes and central to the Lacanian conceptualization of psychosis. Despite the traditional divide between AI research and continental philosophy, this analysis embarks on an innovative journey, utilizing Lacanian philosophy to unravel the logic of AI, using concepts established in the continental discourse on logic, rather than the analytical tradition.</p><h3 id=similar-content-being-viewed-by-others>Similar content being viewed by others
<a class=anchor href=#similar-content-being-viewed-by-others>#</a></h3><h3 id=from-large-language-models-to-small-logic-programs-building-global-explanations-from-disagreeing-local-post-hoc-explainers>From large language models to small logic programs: building global explanations from disagreeing local post-hoc explainers
<a class=anchor href=#from-large-language-models-to-small-logic-programs-building-global-explanations-from-disagreeing-local-post-hoc-explainers>#</a></h3><p data-raw='Article Open access 08 July 2024'>Article Open access 08 July 2024</p><h3 id=large-language-models-could-change-the-future-of-behavioral-healthcare-a-proposal-for-responsible-development-and-evaluation>Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation
<a class=anchor href=#large-language-models-could-change-the-future-of-behavioral-healthcare-a-proposal-for-responsible-development-and-evaluation>#</a></h3><p data-raw='Article Open access 02 April 2024'>Article Open access 02 April 2024</p><h3 id=testing-ai-on-language-comprehension-tasks-reveals-insensitivity-to-underlying-meaning>Testing AI on language comprehension tasks reveals insensitivity to underlying meaning
<a class=anchor href=#testing-ai-on-language-comprehension-tasks-reveals-insensitivity-to-underlying-meaning>#</a></h3><p data-raw='Article Open access 14 November 2024'>Article Open access 14 November 2024</p><p data-raw='
  <a href="https://beta.springernature.com/pre-submission?journalId=146">Use our pre-submission checklist</a>'><a href="https://beta.springernature.com/pre-submission?journalId=146">Use our pre-submission checklist</a></p><p data-raw='Avoid common mistakes on your manuscript.'>Avoid common mistakes on your manuscript.</p><h2 id=1-introduction>1 Introduction
<a class=anchor href=#1-introduction>#</a></h2><p data-raw='In earlier work, we proposed that certain patterns in how AI models, known as Large Language Models (LLMs), make mistakes—or ‘hallucinate’—can be better understood through the lens of Lacanian psychoanalysis. This hypothesis was supported by a theoretical analysis of the possibility of negation in current transformer-based LLMs, and I will briefly describe the main problem here. Since the links between tokens that the LLM processes are determined by probabilities (cf. Brown et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR4" title="Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam P, Sastry G, Askell A, Agarwal S, Herbert-Voss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter C, Amodei D (2020) Language models are few-shot learners. In: NeurIPS 2020. Advance online publication. 
https://doi.org/10.48550/arXiv.2005.14165
">2020</a>), the relational structures established between tokens in an LLM are based on positive relations.<sup><a href="https://link.springer.com/article/10.1007/?utm_source=chatgpt.com#Fn1"><span>Footnote </span>1</a></sup> These relations are established in the training processes and constitute the basic language understanding that LLMs use. The following analysis will focus on two aspects of this mathematical modeling of language: first, that it models language on the basis of metaphor and metonymy, and second, that this model is best described as psychotic in Lacanian terms because of the way it operates with the absence of knowledge. The foundation of current GPT variants, including GPT 3.5 and GPT-4, is rooted in the Transformer architecture as described by Vaswani et al. (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43" title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>), which we will use as a technical reference for analysis.'>In earlier work, we proposed that certain patterns in how AI models, known as Large Language Models (LLMs), make mistakes—or ‘hallucinate’—can be better understood through the lens of Lacanian psychoanalysis. This hypothesis was supported by a theoretical analysis of the possibility of negation in current transformer-based LLMs, and I will briefly describe the main problem here. Since the links between tokens that the LLM processes are determined by probabilities (cf. Brown et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR4 title="Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam P, Sastry G, Askell A, Agarwal S, Herbert-Voss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter C, Amodei D (2020) Language models are few-shot learners. In: NeurIPS 2020. Advance online publication. 
https://doi.org/10.48550/arXiv.2005.14165
">2020</a>), the relational structures established between tokens in an LLM are based on positive relations.<sup><a href="https://link.springer.com/article/10.1007/?utm_source=chatgpt.com#Fn1"><span>Footnote </span>1</a></sup> These relations are established in the training processes and constitute the basic language understanding that LLMs use. The following analysis will focus on two aspects of this mathematical modeling of language: first, that it models language on the basis of metaphor and metonymy, and second, that this model is best described as psychotic in Lacanian terms because of the way it operates with the absence of knowledge. The foundation of current GPT variants, including GPT 3.5 and GPT-4, is rooted in the Transformer architecture as described by Vaswani et al. (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43 title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>), which we will use as a technical reference for analysis.</p><p data-raw='Now, LLMs are currently capable of articulating sentences like “There is no cat”, but this “negation” is based on patterns of positive links between tokens. To put it simply, while LLMs can reproduce some linguistic phenomena, they cheat on negations. In human cognition, we can find several basic structures of negation, all of which intersect and interact with the relational structure of words that constitutes unconscious language, but for LLMs, negation is just another positive pattern in the data, as acknowledged as a problem in several studies (Gubelmann and Handschuh 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR16" title="Gubelmann R, Handschuh S (2022) Context matters: a pragmatic study of PLMs’ negation understanding. In: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pp 4602–4621. 
https://doi.org/10.18653/v1/2022.acl-long.315
">2022</a>; Morante and Blanco 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR36" title="Morante R, Blanco E (2021) Recent advances in processing negation. Nat Lang Eng 27(2):121–130. 
https://doi.org/10.1017/S1351324920000534
">2021</a>). This means that when presented with ambiguous or unknown token combinations, where the model has no positive patterns that allow it to produce an output to say that these combinations are ambiguous (such as the “knowledge cut-off” as a pattern accessible when the input refers to current events), i.e. there is a deficiency in the model’s data, it will necessarily use existing token links. This means that the lack of knowledge is structurally hidden by the system, since it has no way of symbolizing it as such. This leads to hallucinations in which the model exhibits a veracity bias (McKenna et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR31" title="McKenna N, Li T, Cheng L, Hosseini MJ, Johnson M, Steedman M (2023) Sources of Hallucination by large language models on inference tasks. Advance online publication. 
https://doi.org/10.48550/arXiv.2305.14552
">2023</a>). For example, when asked to provide literature on Ridolfo Capo Ferro (a sixteenth century fencing master and the subject of little published research), ChatGPT-4 generated the following hallucination:'>Now, LLMs are currently capable of articulating sentences like “There is no cat”, but this “negation” is based on patterns of positive links between tokens. To put it simply, while LLMs can reproduce some linguistic phenomena, they cheat on negations. In human cognition, we can find several basic structures of negation, all of which intersect and interact with the relational structure of words that constitutes unconscious language, but for LLMs, negation is just another positive pattern in the data, as acknowledged as a problem in several studies (Gubelmann and Handschuh
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR16 title="Gubelmann R, Handschuh S (2022) Context matters: a pragmatic study of PLMs’ negation understanding. In: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pp 4602–4621. 
https://doi.org/10.18653/v1/2022.acl-long.315
">2022</a>; Morante and Blanco
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR36 title="Morante R, Blanco E (2021) Recent advances in processing negation. Nat Lang Eng 27(2):121–130. 
https://doi.org/10.1017/S1351324920000534
">2021</a>). This means that when presented with ambiguous or unknown token combinations, where the model has no positive patterns that allow it to produce an output to say that these combinations are ambiguous (such as the “knowledge cut-off” as a pattern accessible when the input refers to current events), i.e. there is a deficiency in the model’s data, it will necessarily use existing token links. This means that the lack of knowledge is structurally hidden by the system, since it has no way of symbolizing it as such. This leads to hallucinations in which the model exhibits a veracity bias (McKenna et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR31 title="McKenna N, Li T, Cheng L, Hosseini MJ, Johnson M, Steedman M (2023) Sources of Hallucination by large language models on inference tasks. Advance online publication. 
https://doi.org/10.48550/arXiv.2305.14552
">2023</a>). For example, when asked to provide literature on Ridolfo Capo Ferro (a sixteenth century fencing master and the subject of little published research), ChatGPT-4 generated the following hallucination:</p><blockquote><p data-raw='Capo Ferro Revisited: Assessing the Influence of the Renaissance Fencing Master” by [removed] (2013): In this paper, [removed] explores the enduring influence of Ridolfo Capo Ferro on the art of fencing […]. [the author ChatGPT referenced exist and has been removed]'>Capo Ferro Revisited: Assessing the Influence of the Renaissance Fencing Master” by [removed] (2013): In this paper, [removed] explores the enduring influence of Ridolfo Capo Ferro on the art of fencing […]. [the author ChatGPT referenced exist and has been removed]</p></blockquote><p data-raw='The process of achieving this is fairly straightforward, although it does require expertise in a field that is not immediately aligned with common knowledge: Ask GPT-3.5 or 4 for detailed references to a research area without labeling it as a knowledge gap. This approach is strategic: if your query suggests a research gap the GPT may default to making connections based on its knowledge of research gaps. GPT-4 Turbo, on the other hand, shows much more careful production of fake scientific literature, likely a response by OpenAI to the widely discussed problem of fake papers. Conversely, by asking a question about a topic where basic knowledge exists (such as HEMA sports as a modern recreation of 16th-century fencing) but substantial academic research is lacking, you encourage the GPT to bridge its little existing knowledge with the naming conventions of scientific articles. This facilitates a unique metaphorical link between the associative fringes of knowledge it can access and the structured format of academic literature. However, when applied to commonly known unknowns (as fake scientific papers are for GPT-4 Turbo), this will of course almost always produce the common knowledge of that unknown. While this paper is not in existence, this response is still generated by linking token representations to create a plausible response on the basis of the training data. This response demonstrates the model’s attempt to navigate the ambiguous concept by making connections to familiar authors and concepts, as determined by the weights assigned to tokens associated with Capo Ferro, fencing, and the sixteenth century. When asked to elaborate, ChatGPT will even hallucinate more details. It is important to note that the model does not detect this behavior itself, but instead simulates a sense of coherence. It associates around the constituted connection that the attention mechanism has provided to it through the prompt, without recognizing the lack of knowledge introduced by the prompt, which constitutes an unknown object outside of its training data (cf. 2.1). This reflects the formal structure of strong certainty that masks an underlying void or ambiguity, which is the main symptom of psychosis in humans (Leader 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30" title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 117). This parallel to the psychotic has been discussed in passing in the previous analysis, but requires more detailed analysis, especially in terms of determining the capabilities of LLMs.'>The process of achieving this is fairly straightforward, although it does require expertise in a field that is not immediately aligned with common knowledge: Ask GPT-3.5 or 4 for detailed references to a research area without labeling it as a knowledge gap. This approach is strategic: if your query suggests a research gap the GPT may default to making connections based on its knowledge of research gaps. GPT-4 Turbo, on the other hand, shows much more careful production of fake scientific literature, likely a response by OpenAI to the widely discussed problem of fake papers. Conversely, by asking a question about a topic where basic knowledge exists (such as HEMA sports as a modern recreation of 16th-century fencing) but substantial academic research is lacking, you encourage the GPT to bridge its little existing knowledge with the naming conventions of scientific articles. This facilitates a unique metaphorical link between the associative fringes of knowledge it can access and the structured format of academic literature. However, when applied to commonly known unknowns (as fake scientific papers are for GPT-4 Turbo), this will of course almost always produce the common knowledge of that unknown. While this paper is not in existence, this response is still generated by linking token representations to create a plausible response on the basis of the training data. This response demonstrates the model’s attempt to navigate the ambiguous concept by making connections to familiar authors and concepts, as determined by the weights assigned to tokens associated with Capo Ferro, fencing, and the sixteenth century. When asked to elaborate, ChatGPT will even hallucinate more details. It is important to note that the model does not detect this behavior itself, but instead simulates a sense of coherence. It associates around the constituted connection that the attention mechanism has provided to it through the prompt, without recognizing the lack of knowledge introduced by the prompt, which constitutes an unknown object outside of its training data (cf. 2.1). This reflects the formal structure of strong certainty that masks an underlying void or ambiguity, which is the main symptom of psychosis in humans (Leader
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30 title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 117). This parallel to the psychotic has been discussed in passing in the previous analysis, but requires more detailed analysis, especially in terms of determining the capabilities of LLMs.</p><p data-raw='However, this parallel to the subjective structure of the psychotic that modern psychoanalysis has identified in human hallucinations is more than a metaphorical connection. This parallel is most visible in the hallucinations of LLMs because Lacan’s theory of psychosis holds that psychotics have foreclosed parts of their linguistic representational or transcendental system, and psychosis itself is the structure of subjectivity that makes sense by circling around these missing parts (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR25" title="Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company">1993</a>, pp. 45–46). Just as LLMs circle around the unacknowledged unknown, psychotic hallucinations are thought to be structured by a structurally comparable circling around a void that necessitates “new signifying effects” (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR28" title="Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton">2006</a>, p. 447), which are primarily verbal hallucinations (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR25" title="Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company">1993</a>, p. 36), that is, constructed directly through language. The product of this circling around a void may be highly individualized, but the formal structure of the foreclosure is not. This formal structure of foreclosure, the inability to conceptualize the underlying void, not the subjective experience of psychosis, mirrors the formal structure exhibited by LLMs. Now, while LLMs may produce results that appear nonsensical or detached from reality due to their probabilistic associations, equating this with human psychosis may seem reductive. Given that Lacanian psychoanalysis focuses on the formal and logical analysis of psychosis, especially in its non-dramatic, ordinary form (Miller 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR35" title="Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytical Notebooks: Symptoms (Vol 7)">2002</a>), and explicitly does not focus on its possible genetic or neurochemical origins (Leader 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30" title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 28), it also allows for an easier bridge between human cognition and AI than behavioral or medical analysis. More importantly, as the use of psychoanalytic concepts since Freud shows, it is not limited to the clinic and, if used outside of clinical practice, should be practiced as “the method that proceeds with the deciphering of signifiers without concern for any form of presumed existence of the signified” (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR28" title="Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton">2006</a>, p. 630), i.e., as a logic of the unconscious..'>However, this parallel to the subjective structure of the psychotic that modern psychoanalysis has identified in human hallucinations is more than a metaphorical connection. This parallel is most visible in the hallucinations of LLMs because Lacan’s theory of psychosis holds that psychotics have foreclosed parts of their linguistic representational or transcendental system, and psychosis itself is the structure of subjectivity that makes sense by circling around these missing parts (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR25 title="Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company">1993</a>, pp. 45–46). Just as LLMs circle around the unacknowledged unknown, psychotic hallucinations are thought to be structured by a structurally comparable circling around a void that necessitates “new signifying effects” (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR28 title="Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton">2006</a>, p. 447), which are primarily verbal hallucinations (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR25 title="Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company">1993</a>, p. 36), that is, constructed directly through language. The product of this circling around a void may be highly individualized, but the formal structure of the foreclosure is not. This formal structure of foreclosure, the inability to conceptualize the underlying void, not the subjective experience of psychosis, mirrors the formal structure exhibited by LLMs. Now, while LLMs may produce results that appear nonsensical or detached from reality due to their probabilistic associations, equating this with human psychosis may seem reductive. Given that Lacanian psychoanalysis focuses on the formal and logical analysis of psychosis, especially in its non-dramatic, ordinary form (Miller
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR35 title="Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytical Notebooks: Symptoms (Vol 7)">2002</a>), and explicitly does not focus on its possible genetic or neurochemical origins (Leader
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30 title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 28), it also allows for an easier bridge between human cognition and AI than behavioral or medical analysis. More importantly, as the use of psychoanalytic concepts since Freud shows, it is not limited to the clinic and, if used outside of clinical practice, should be practiced as “the method that proceeds with the deciphering of signifiers without concern for any form of presumed existence of the signified” (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR28 title="Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton">2006</a>, p. 630), i.e., as a logic of the unconscious..</p><p data-raw='This concept of a “logic of the unconscious” signals a move away from the Aristotelian, proposition-centered view of logic and toward the understanding of logic advocated by Heidegger and evident in the work of Freud and Lacan. Assuming that logic, which serves as the structured basis for linguistic inference, is structured by relational connections between words-what Heidegger called “as-relation”-implies a reevaluation of traditional propositional logic in favor of a relational approach.<sup><a href="https://link.springer.com/article/10.1007/?utm_source=chatgpt.com#Fn2"><span>Footnote </span>2</a></sup> Even when considering individual letters, Heidegger emphasized that “‘Something as something’ [is] in the background!” (Heidegger 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR18" title="Heidegger M (2007) Basic concepts of ancient philosophy. Studies in continental thought ser. Indiana University Press">2007</a>, p. 113), showing that for Heidegger the framework of signifying relations, consisting of interrelated elements and indicative directions, is present even at the level of individual letters, thus facilitating a direct connection to the signifier in Lacanian theory. For both Heidegger and Lacan, the essence of logic is the question of how this structure of links relates to the absent and the negated.'>This concept of a “logic of the unconscious” signals a move away from the Aristotelian, proposition-centered view of logic and toward the understanding of logic advocated by Heidegger and evident in the work of Freud and Lacan. Assuming that logic, which serves as the structured basis for linguistic inference, is structured by relational connections between words-what Heidegger called “as-relation”-implies a reevaluation of traditional propositional logic in favor of a relational approach.<sup><a href="https://link.springer.com/article/10.1007/?utm_source=chatgpt.com#Fn2"><span>Footnote </span>2</a></sup> Even when considering individual letters, Heidegger emphasized that “‘Something as something’ [is] in the background!” (Heidegger
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR18 title="Heidegger M (2007) Basic concepts of ancient philosophy. Studies in continental thought ser. Indiana University Press">2007</a>, p. 113), showing that for Heidegger the framework of signifying relations, consisting of interrelated elements and indicative directions, is present even at the level of individual letters, thus facilitating a direct connection to the signifier in Lacanian theory. For both Heidegger and Lacan, the essence of logic is the question of how this structure of links relates to the absent and the negated.</p><p data-raw='This formal problem has been explored as what Hans Blumenberg has called the “absolute metaphor” (Blumenberg and Savage 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR3" title="Blumenberg H, Savage RI (2010) Paradigms for a metaphorology. Signale. Cornell University Press">2010</a>), which marks the phenomenon of a necessary absence or indeterminacy structuring a formal system of thought, deeply connected to the metaphoric and metonymic linking in our linguistic systems. In this way, this type of logic is distinguished from a psychologistic understanding of logic. It includes the absent as a core moment that is only accessible as a formal element. Psychosis, as Lacan conceptualizes it at the level of logic and language, then marks two elements of cognition centered on voids or absences. First, psychosis marks the inability to relate to these absolute metaphors, and psychotics demonstrate a specific relationship to these absences that mirrors LLM hallucinations. Second, since human cognition, as conceptualized by Lacan, always involves aspects of psychosis, this hallucinatory circuit may be more than a failure of modern AI models but may instead offer a more complex approach to AI and cognition. Finally, there are structural similarities between hallucinations and absolute metaphors, meaning that while current AI models may only be able to hallucinate rather than refer to absolute metaphors, they may not be entirely inaccessible.'>This formal problem has been explored as what Hans Blumenberg has called the “absolute metaphor” (Blumenberg and Savage
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR3 title="Blumenberg H, Savage RI (2010) Paradigms for a metaphorology. Signale. Cornell University Press">2010</a>), which marks the phenomenon of a necessary absence or indeterminacy structuring a formal system of thought, deeply connected to the metaphoric and metonymic linking in our linguistic systems. In this way, this type of logic is distinguished from a psychologistic understanding of logic. It includes the absent as a core moment that is only accessible as a formal element. Psychosis, as Lacan conceptualizes it at the level of logic and language, then marks two elements of cognition centered on voids or absences. First, psychosis marks the inability to relate to these absolute metaphors, and psychotics demonstrate a specific relationship to these absences that mirrors LLM hallucinations. Second, since human cognition, as conceptualized by Lacan, always involves aspects of psychosis, this hallucinatory circuit may be more than a failure of modern AI models but may instead offer a more complex approach to AI and cognition. Finally, there are structural similarities between hallucinations and absolute metaphors, meaning that while current AI models may only be able to hallucinate rather than refer to absolute metaphors, they may not be entirely inaccessible.</p><p data-raw='Such a central position of the void as a formal element of thought has been described in detail by Lacan and thinkers following the lines of thought he opened. There is little overlap between AI research and the analysis of logic in continental philosophy, due to the inherent orientation of computer and information science to the Anglo–Saxon tradition of analytic philosophy (Priestley 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR40" title="Priestley M (2011) A science of operations. Springer, London. 
https://doi.org/10.1007/978-1-84882-555-0
">2011</a>). And while certain forms of contradiction may have been the focus of analytically trained thinkers, for example Graham Priest (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR39" title="Priest G (2006) In contradiction: a study of the transconsistent, Expanded. Clarendon Press">2006</a>). The logical analysis of absence as an indeterminate element has been a project exclusively undertaken by continental thinkers such as Lacan or, more recently, Alain Badiou (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1" title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>). This means using continental philosophy not as a resource for thinking about human existence, but as a resource for the discussion of logic, language, and ontology that this tradition has also focused on. However, the discourse on AI still grapples with a lack of theoretical exploration into how computation distorts symbolic recognition. Despite the integration of Lacanian theory into various research domains, discussions on the ontology of logic within AI studies remain scarce. Central contributors to the continental discourse on logic like Alain Badiou (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1" title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>), Jacques-Alain Miller (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR35" title="Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytical Notebooks: Symptoms (Vol 7)">2002</a>), Ellie Ragland-Sullivan (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR41" title="Ragland-Sullivan E (2015) Jacques Lacan and the logic of structure: topology and language in psychoanalysis. Routledge">2015</a>), and Alenka Zupančič (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR48" title="Zupančič A (2017) What is sex? MIT Press">2017</a>) have primarily addressed clinical or political issues, while recent works by Isabell Millar (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR33" title="Millar I (2021) The psychoanalysis of artificial intelligence (1st ed. 2021). Springer eBook Collection. Springer International Publishing; Imprint Palgrave Macmillan. 
https://doi.org/10.1007/978-3-030-67981-1
">2021</a>), André Nusselder (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR37" title="Nusselder AC (2006) Interface fantasy: a Lacanian Cyborg Ontology: Een Lacaniaanse Cyborg Ontologie = Interface fantasie. Zugl.: Rotterdam, Univ., Diss., 2006. F&amp;N Eigen Beheer">2006</a>), Jacob Johanssen (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR24" title="Johanssen J (2018) Psychoanalysis and digital culture: audiences, social media, and big data. Routledge Studies in New Media and Cyberculture Ser. Routledge">2018</a>), and Matthew Flisfeder (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR11" title="Flisfeder M (2021) Algorithmic desire: toward a new structuralist theory of social media. Diaeresis. Northwestern University Press">2021</a>) on computational challenges tend to explore AI and computation through a Lacanian analysis of fantasies, marking the deeper issue that Clint Burnham (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR5" title="Burnham C (2022) Siri, what is psychoanalysis? Psychoanal Cult Soc Adv Online Publ. 
https://doi.org/10.1057/s41282-022-00294-0
">2022</a>) describes as the “phallic appearance” of computers, that is their imaginary tendencies. However, the logic in which the algorithmic “Big Other’s” failure should be marked is not explored in detail. Johansson analysis of big data’s perverse aspect and Rambatan and Johansson’s (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR42" title="Rambatan B, Johanssen J (2022) Event horizon: sexuality, politics, online culture, and the limits of capitalism. John Hunt Publishing Limited">2022</a>) identification of a fundamental “misrecognition” in big data points into the direction we will approach here, if read through the lens of Lacan’s logic. This means, one has to mark this misrecognition as imaginary in the very specific sense that Lacan offers us, as assuming the coherence of the symbolic and foreclosing the real. By integrating Lacanian psychoanalytic concepts of the logic of psychosis, we apply these principles to the core architecture of language modeling in large language models (LLMs).'>Such a central position of the void as a formal element of thought has been described in detail by Lacan and thinkers following the lines of thought he opened. There is little overlap between AI research and the analysis of logic in continental philosophy, due to the inherent orientation of computer and information science to the Anglo–Saxon tradition of analytic philosophy (Priestley
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR40 title="Priestley M (2011) A science of operations. Springer, London. 
https://doi.org/10.1007/978-1-84882-555-0
">2011</a>). And while certain forms of contradiction may have been the focus of analytically trained thinkers, for example Graham Priest (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR39 title="Priest G (2006) In contradiction: a study of the transconsistent, Expanded. Clarendon Press">2006</a>). The logical analysis of absence as an indeterminate element has been a project exclusively undertaken by continental thinkers such as Lacan or, more recently, Alain Badiou (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1 title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>). This means using continental philosophy not as a resource for thinking about human existence, but as a resource for the discussion of logic, language, and ontology that this tradition has also focused on. However, the discourse on AI still grapples with a lack of theoretical exploration into how computation distorts symbolic recognition. Despite the integration of Lacanian theory into various research domains, discussions on the ontology of logic within AI studies remain scarce. Central contributors to the continental discourse on logic like Alain Badiou (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1 title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>), Jacques-Alain Miller (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR35 title="Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytical Notebooks: Symptoms (Vol 7)">2002</a>), Ellie Ragland-Sullivan (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR41 title="Ragland-Sullivan E (2015) Jacques Lacan and the logic of structure: topology and language in psychoanalysis. Routledge">2015</a>), and Alenka Zupančič (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR48 title="Zupančič A (2017) What is sex? MIT Press">2017</a>) have primarily addressed clinical or political issues, while recent works by Isabell Millar (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR33 title="Millar I (2021) The psychoanalysis of artificial intelligence (1st ed. 2021). Springer eBook Collection. Springer International Publishing; Imprint Palgrave Macmillan. 
https://doi.org/10.1007/978-3-030-67981-1
">2021</a>), André Nusselder (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR37 title="Nusselder AC (2006) Interface fantasy: a Lacanian Cyborg Ontology: Een Lacaniaanse Cyborg Ontologie = Interface fantasie. Zugl.: Rotterdam, Univ., Diss., 2006. F&amp;N Eigen Beheer">2006</a>), Jacob Johanssen (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR24 title="Johanssen J (2018) Psychoanalysis and digital culture: audiences, social media, and big data. Routledge Studies in New Media and Cyberculture Ser. Routledge">2018</a>), and Matthew Flisfeder (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR11 title="Flisfeder M (2021) Algorithmic desire: toward a new structuralist theory of social media. Diaeresis. Northwestern University Press">2021</a>) on computational challenges tend to explore AI and computation through a Lacanian analysis of fantasies, marking the deeper issue that Clint Burnham (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR5 title="Burnham C (2022) Siri, what is psychoanalysis? Psychoanal Cult Soc Adv Online Publ. 
https://doi.org/10.1057/s41282-022-00294-0
">2022</a>) describes as the “phallic appearance” of computers, that is their imaginary tendencies. However, the logic in which the algorithmic “Big Other’s” failure should be marked is not explored in detail. Johansson analysis of big data’s perverse aspect and Rambatan and Johansson’s (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR42 title="Rambatan B, Johanssen J (2022) Event horizon: sexuality, politics, online culture, and the limits of capitalism. John Hunt Publishing Limited">2022</a>) identification of a fundamental “misrecognition” in big data points into the direction we will approach here, if read through the lens of Lacan’s logic. This means, one has to mark this misrecognition as imaginary in the very specific sense that Lacan offers us, as assuming the coherence of the symbolic and foreclosing the real. By integrating Lacanian psychoanalytic concepts of the logic of psychosis, we apply these principles to the core architecture of language modeling in large language models (LLMs).</p><p data-raw='The following paper will approach this problem in several steps, following this introduction (I). First, we will discuss why it is possible to read the model of language that an LLM uses as based on a mathematical model of “metaphor and metonymy” (II), and how prompting creates metaphorical links between tokens (II.1). The next step is to see how absolute metaphors structure the field of meaning constructed by metaphor and metonymy (III). Finally, by comparing the specific structure of psychosis, we can discuss the foreclosure (IV) that modern AIs seem to exhibit. Finally, we will consider the consequences of this parallel (V).'>The following paper will approach this problem in several steps, following this introduction (I). First, we will discuss why it is possible to read the model of language that an LLM uses as based on a mathematical model of “metaphor and metonymy” (II), and how prompting creates metaphorical links between tokens (II.1). The next step is to see how absolute metaphors structure the field of meaning constructed by metaphor and metonymy (III). Finally, by comparing the specific structure of psychosis, we can discuss the foreclosure (IV) that modern AIs seem to exhibit. Finally, we will consider the consequences of this parallel (V).</p><h2 id=2-metaphor-and-metonymy>2 Metaphor and metonymy
<a class=anchor href=#2-metaphor-and-metonymy>#</a></h2><p data-raw='The suggestion that token linking should be read as metaphorical and metonymic rather than probabilistic may come as a surprise. The probabilistic nature of LLMs is repeated in most publications on them, and the derisive “stochastic parrot” introduced by Bender et al. (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR2" title="Bender EM, Gebru T, McMillan-Major A, Shmitchell S (2021) On the Dangers of Stochastic Parrots. In: FAccT‘21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp 610–623. 
https://doi.org/10.1145/3442188.3445922
">2021</a>) informs this reading. The processing of the input in an LLM is undoubtedly structured by the probabilistic inference of the following token (cf. Vaswani et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43" title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>). However, looking at the model of language that we find in the decoder blocks of an LLM such as GPT-3, we can make a different argument, because the weighted token connections in the embeddings, their representation by a dynamic multidimensional vector (a term we take from Vaswani et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43" title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>, p. 5) made up of probabilistic connections, should be understood as the core of the actual model at hand, i.e. the digital model of human language capable of generating meaningful text. What this system models is the relational structure that connects words and subwords through everyday practice and literature, which manifests itself as a tradition of language use. To be as direct as possible: we do not deny that LLMs operate on statistical principles, that is “how” the model of the language they use works, “what” is modeled is the dynamic relationship of words based on association and use. Because of this ‘how’ of modeling, its reliance on a specific approach to applied mathematics, and its inability to use absences, its approach to modeling is incomplete. However, the “what” that is modeled, while limited by the “how,” still marks an impressive approach to language that demonstrates central ideas about language (such as Freud’s) that have been derided in favor of systematic, rule-oriented interpretations of language.'>The suggestion that token linking should be read as metaphorical and metonymic rather than probabilistic may come as a surprise. The probabilistic nature of LLMs is repeated in most publications on them, and the derisive “stochastic parrot” introduced by Bender et al. (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR2 title="Bender EM, Gebru T, McMillan-Major A, Shmitchell S (2021) On the Dangers of Stochastic Parrots. In: FAccT‘21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp 610–623. 
https://doi.org/10.1145/3442188.3445922
">2021</a>) informs this reading. The processing of the input in an LLM is undoubtedly structured by the probabilistic inference of the following token (cf. Vaswani et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43 title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>). However, looking at the model of language that we find in the decoder blocks of an LLM such as GPT-3, we can make a different argument, because the weighted token connections in the embeddings, their representation by a dynamic multidimensional vector (a term we take from Vaswani et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43 title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>, p. 5) made up of probabilistic connections, should be understood as the core of the actual model at hand, i.e. the digital model of human language capable of generating meaningful text. What this system models is the relational structure that connects words and subwords through everyday practice and literature, which manifests itself as a tradition of language use. To be as direct as possible: we do not deny that LLMs operate on statistical principles, that is “how” the model of the language they use works, “what” is modeled is the dynamic relationship of words based on association and use. Because of this ‘how’ of modeling, its reliance on a specific approach to applied mathematics, and its inability to use absences, its approach to modeling is incomplete. However, the “what” that is modeled, while limited by the “how,” still marks an impressive approach to language that demonstrates central ideas about language (such as Freud’s) that have been derided in favor of systematic, rule-oriented interpretations of language.</p><p data-raw='These links will be discussed below as representing the metonymic and metaphoric links between words in human language use. Metaphor and metonymy are both formal elements of language that involve the substitution of one term for another. However, the basis of their substitutions and their implications are different. Metaphors are based on similarities or analogies, which are sometimes newly established by these metaphors, while metonymies are based on close associations or links between the terms in question. The metonymic ability to understand one thing in terms of another that is contextually close, to derive meaning by metaphorically juxtaposing disparate elements, and to conceptualize abstract concepts through concrete examples are central features of human understanding. They constitute a fundamental structure of human language, and when these functions are damaged, human language shifts dramatically as Roman Jakobson ([1896] 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR23" title="Jakobson R (1987) Language in literature. Belknap Press of Harvard Univ, Press">1987</a>, pp. 95–114) argued. This means that if we assume that metaphor and metonymy are central to human language, we assume that language is built on connections between words. These words derive their meaning only from these connections as they form the metonymic context, while a connection that transcends these contextual networks is a metaphor.'>These links will be discussed below as representing the metonymic and metaphoric links between words in human language use. Metaphor and metonymy are both formal elements of language that involve the substitution of one term for another. However, the basis of their substitutions and their implications are different. Metaphors are based on similarities or analogies, which are sometimes newly established by these metaphors, while metonymies are based on close associations or links between the terms in question. The metonymic ability to understand one thing in terms of another that is contextually close, to derive meaning by metaphorically juxtaposing disparate elements, and to conceptualize abstract concepts through concrete examples are central features of human understanding. They constitute a fundamental structure of human language, and when these functions are damaged, human language shifts dramatically as Roman Jakobson ([1896]
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR23 title="Jakobson R (1987) Language in literature. Belknap Press of Harvard Univ, Press">1987</a>, pp. 95–114) argued. This means that if we assume that metaphor and metonymy are central to human language, we assume that language is built on connections between words. These words derive their meaning only from these connections as they form the metonymic context, while a connection that transcends these contextual networks is a metaphor.</p><p data-raw='This is what LLMs seem to mimic. Their mathematical structures allow token representations to be intertwined in a way that strongly resembles this metaphorical and metonymical linking. We argue that the formal structure of metaphor and metonymy in natural language is reproduced in the mathematical architecture of LLMs. In particular, a possible resistance to this understanding of language will assume that human language use is at its core structured by sentences and inferences, i.e., following Chomsky’s form of linguistics (see e.g., this critique of LLMs: Chomsky et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR7" title="Chomsky N, Roberts I, Watumull J (2023) The false promise of ChatGPT. In: New York Times, 
https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html
">2023</a>). We argue, however, that the actual modeling of language by LLMs reflects the way continental philosophers and psychoanalysts understand language. Two conclusions would then follow: first, that the model argued for by continental philosophers and psychoanalysts, when replicated by a machine, is indeed quite capable of producing the inference that Chomsky considers fundamental (since specialized GPTs are capable of programming), and second, that predicative inference must be understood on the basis of other forms of logical structure.'>This is what LLMs seem to mimic. Their mathematical structures allow token representations to be intertwined in a way that strongly resembles this metaphorical and metonymical linking. We argue that the formal structure of metaphor and metonymy in natural language is reproduced in the mathematical architecture of LLMs. In particular, a possible resistance to this understanding of language will assume that human language use is at its core structured by sentences and inferences, i.e., following Chomsky’s form of linguistics (see e.g., this critique of LLMs: Chomsky et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR7 title="Chomsky N, Roberts I, Watumull J (2023) The false promise of ChatGPT. In: New York Times, 
https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html
">2023</a>). We argue, however, that the actual modeling of language by LLMs reflects the way continental philosophers and psychoanalysts understand language. Two conclusions would then follow: first, that the model argued for by continental philosophers and psychoanalysts, when replicated by a machine, is indeed quite capable of producing the inference that Chomsky considers fundamental (since specialized GPTs are capable of programming), and second, that predicative inference must be understood on the basis of other forms of logical structure.</p><p data-raw='To ensure clarity in our discussion, it is important to distinguish the theoretical basis of our approach to metaphor from that of Lakoff and Johnson (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR29" title="Lakoff G, Johnson M (2011) Metaphors we live by: with a new afterword (6. print). Univ of Chicago Press">2011</a>) in “Metaphors We Live By.” Although their work provides a nuanced interpretation rooted in the Aristotelian tradition of metaphor as a means of substituting one frame of reference for another, it does not encompass the exploration of absolute metaphors as extensively outlined by Blumenberg, nor does it engage with the concepts as articulated by thinkers like Heidegger, Freud, and Lacan. Given our focus on the interplay between metaphorical expressions and the formal structure of voids, the framework offered by Lakoff and Johnson, while valuable, does not directly inform the subsequent analysis.'>To ensure clarity in our discussion, it is important to distinguish the theoretical basis of our approach to metaphor from that of Lakoff and Johnson (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR29 title="Lakoff G, Johnson M (2011) Metaphors we live by: with a new afterword (6. print). Univ of Chicago Press">2011</a>) in “Metaphors We Live By.” Although their work provides a nuanced interpretation rooted in the Aristotelian tradition of metaphor as a means of substituting one frame of reference for another, it does not encompass the exploration of absolute metaphors as extensively outlined by Blumenberg, nor does it engage with the concepts as articulated by thinkers like Heidegger, Freud, and Lacan. Given our focus on the interplay between metaphorical expressions and the formal structure of voids, the framework offered by Lakoff and Johnson, while valuable, does not directly inform the subsequent analysis.</p><p data-raw='Returning to the Aristotelian concept of a metaphor, as Lakoff and Johnson do, still helps us avoid one form of misunderstanding: that metaphors are tied to imaginary impressions or experiences. Take William Blake’s metaphor: “the meadows laugh with lively green”: it is not a visual impression, but a linguistic connection that can be formalized as the transposition of a concept (laugh), which constitutes its meaning through one context (human behavior), into another context (the meadow). While “green” and “meadow” are already linked in a metonymic structure, i.e. they could stand for each other without changing the meaning of a sentence (exemplified by “the green” as a metonymic substitute for meadows), laughing is not. The metaphorical operation thus links two different field or contextual networks of signifiers (for a detailed discussion of metaphor and metonymy, see Jakobson 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR23" title="Jakobson R (1987) Language in literature. Belknap Press of Harvard Univ, Press">1987</a>). Notably, this description of metaphor does not rely on existential experience or cognition, so it is unproblematic to assume that a mathematical model can stand for it.'>Returning to the Aristotelian concept of a metaphor, as Lakoff and Johnson do, still helps us avoid one form of misunderstanding: that metaphors are tied to imaginary impressions or experiences. Take William Blake’s metaphor: “the meadows laugh with lively green”: it is not a visual impression, but a linguistic connection that can be formalized as the transposition of a concept (laugh), which constitutes its meaning through one context (human behavior), into another context (the meadow). While “green” and “meadow” are already linked in a metonymic structure, i.e. they could stand for each other without changing the meaning of a sentence (exemplified by “the green” as a metonymic substitute for meadows), laughing is not. The metaphorical operation thus links two different field or contextual networks of signifiers (for a detailed discussion of metaphor and metonymy, see Jakobson
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR23 title="Jakobson R (1987) Language in literature. Belknap Press of Harvard Univ, Press">1987</a>). Notably, this description of metaphor does not rely on existential experience or cognition, so it is unproblematic to assume that a mathematical model can stand for it.</p><p data-raw='Applying this structure of metonymy and metaphor as the core of the connection of signifiers also allows us to mark the similarity to LLMs, reflecting the result of statistical analysis, the model itself consists of vectors, representing the tokens that have been input by the user, accompanied by their intrinsic weights and connections to other vectors. This representation, while fundamentally mathematical, encapsulates intricate semantic and syntactic connections between words, phrases, and larger linguistic constructs as patterns of vectors in close multidimensional proximity within the embedding space. This leads to the surprising ability of LLMs to translate. Conneau et al. (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR8" title="Conneau A, Lample G, Ranzato M, Denoyer L, Jégou H (2017) Word translation without parallel data. Advance online publication. 
https://doi.org/10.48550/arXiv.1710.04087
">2017</a>) propose a method that autonomously aligns the embedding spaces of two languages by exploiting the underlying structure of these spaces, which they found to have striking similarities across languages. Translated into language theory, this means that the associative mapping of word meanings shows parallels across languages, which is not surprising, but it is this proximity in the embedding space of, for example, “green” and “grün” that makes this translation possible. Now, these embeddings in the embedding space are dynamically exploited by the multidirectional reading of the input (introduced in Devlin et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR9" title="Devlin J, Chang M‑W, Lee K, Toutanova K (2018) BERT: pre-training of deep bidirectional transformers for language understanding. Advance online publication. 
https://doi.org/10.48550/arXiv.1810.04805
">2018</a>). This means that modern LLMs are able to dynamically adjust the links between these vectors representing words and patterns through positional encoding and self-attention. This means that the input prompt can link patterns as contextual within a single chat that are not linked in the trained data. The dynamism of these embeddings comes from the model’s ability to generate context-specific representations for each token based on its current context. The transformer’s ability to adjust embeddings based on the entire input sequence context ensures that even novel combinations like an input of “write ~ dream” (which would mark a identification of the words “dream” and “write” through the tilde), even if split into separate tokens, are processed in a way that the semantic and conceptual links between these tokens are recognized and emphasized. The vector representations of the input of “write” and “dream” are then moved into closer proximity. Since LLMs map their understanding of words and sentences solely on the basis of these vector representations and their proximity and replaceability, we are dealing with the convergence of mathematical models and metonymical understanding. While the LLM operates on probabilities and is generated by statistical analysis, the resulting network of representations seems to tap into a pre-predicative structure of language. If this is the case, it would lend credence to the argument that human linguistic structures are metonymic and metaphoric in nature, and that LLMs inadvertently capture this essence.'>Applying this structure of metonymy and metaphor as the core of the connection of signifiers also allows us to mark the similarity to LLMs, reflecting the result of statistical analysis, the model itself consists of vectors, representing the tokens that have been input by the user, accompanied by their intrinsic weights and connections to other vectors. This representation, while fundamentally mathematical, encapsulates intricate semantic and syntactic connections between words, phrases, and larger linguistic constructs as patterns of vectors in close multidimensional proximity within the embedding space. This leads to the surprising ability of LLMs to translate. Conneau et al. (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR8 title="Conneau A, Lample G, Ranzato M, Denoyer L, Jégou H (2017) Word translation without parallel data. Advance online publication. 
https://doi.org/10.48550/arXiv.1710.04087
">2017</a>) propose a method that autonomously aligns the embedding spaces of two languages by exploiting the underlying structure of these spaces, which they found to have striking similarities across languages. Translated into language theory, this means that the associative mapping of word meanings shows parallels across languages, which is not surprising, but it is this proximity in the embedding space of, for example, “green” and “grün” that makes this translation possible. Now, these embeddings in the embedding space are dynamically exploited by the multidirectional reading of the input (introduced in Devlin et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR9 title="Devlin J, Chang M‑W, Lee K, Toutanova K (2018) BERT: pre-training of deep bidirectional transformers for language understanding. Advance online publication. 
https://doi.org/10.48550/arXiv.1810.04805
">2018</a>). This means that modern LLMs are able to dynamically adjust the links between these vectors representing words and patterns through positional encoding and self-attention. This means that the input prompt can link patterns as contextual within a single chat that are not linked in the trained data. The dynamism of these embeddings comes from the model’s ability to generate context-specific representations for each token based on its current context. The transformer’s ability to adjust embeddings based on the entire input sequence context ensures that even novel combinations like an input of “write ~ dream” (which would mark a identification of the words “dream” and “write” through the tilde), even if split into separate tokens, are processed in a way that the semantic and conceptual links between these tokens are recognized and emphasized. The vector representations of the input of “write” and “dream” are then moved into closer proximity. Since LLMs map their understanding of words and sentences solely on the basis of these vector representations and their proximity and replaceability, we are dealing with the convergence of mathematical models and metonymical understanding. While the LLM operates on probabilities and is generated by statistical analysis, the resulting network of representations seems to tap into a pre-predicative structure of language. If this is the case, it would lend credence to the argument that human linguistic structures are metonymic and metaphoric in nature, and that LLMs inadvertently capture this essence.</p><p data-raw='This means that the links between words and subwords that the LLM models are links between vectors representing tokens, not sentences or hierarchical systems of meaning. Therefore, to compare the actual model that LLMs provide to human language use, we need to compare it to the linking between words that is inherent in human language. That is, the statistical basis is the way in which the link between words is emulated, it is an aspect and a tool of this modeling, but it is not sufficient to explain why this model could reflect human language use. While the probabilistic element can even be considered central to the result, it is not the only thing to consider in terms of how formal and mathematical reasoning is used to model something. Any form of mathematical modeling succeeds not only because it is mathematically sound and well-engineered, but also because it succeeds in modeling something that is not inherently mathematical. In language, however, the distance between the ontological status of the model and the object it models is short, since both are symbolic systems. Even if we consider the specific mode of this linkage to be probabilistic or statistical, the model of language, the way language is constructed, as this acquired, multidimensional, vector-oriented representation is used here, is much more comparable to how Freud analyzed the memory structures embedded in dreams in “Traumdeutung” (see e.g. Freud 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR14" title="Freud S (1942) Gesammelte Werke: zweiter und dritter Band. Die Traumdeutung: Über den Traum (A. Freud, Ed.). S. Fischer">1942</a>, pp. 154–155) than to Chomsky’s “Syntactic Structures” (Chomsky 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR6" title="Chomsky N (2002) Syntactic structures. A Mouton classic, 2nd edn. Mouton de Gruyter">2002</a>):'>This means that the links between words and subwords that the LLM models are links between vectors representing tokens, not sentences or hierarchical systems of meaning. Therefore, to compare the actual model that LLMs provide to human language use, we need to compare it to the linking between words that is inherent in human language. That is, the statistical basis is the way in which the link between words is emulated, it is an aspect and a tool of this modeling, but it is not sufficient to explain why this model could reflect human language use. While the probabilistic element can even be considered central to the result, it is not the only thing to consider in terms of how formal and mathematical reasoning is used to model something. Any form of mathematical modeling succeeds not only because it is mathematically sound and well-engineered, but also because it succeeds in modeling something that is not inherently mathematical. In language, however, the distance between the ontological status of the model and the object it models is short, since both are symbolic systems. Even if we consider the specific mode of this linkage to be probabilistic or statistical, the model of language, the way language is constructed, as this acquired, multidimensional, vector-oriented representation is used here, is much more comparable to how Freud analyzed the memory structures embedded in dreams in “Traumdeutung” (see e.g. Freud
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR14 title="Freud S (1942) Gesammelte Werke: zweiter und dritter Band. Die Traumdeutung: Über den Traum (A. Freud, Ed.). S. Fischer">1942</a>, pp. 154–155) than to Chomsky’s “Syntactic Structures” (Chomsky
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR6 title="Chomsky N (2002) Syntactic structures. A Mouton classic, 2nd edn. Mouton de Gruyter">2002</a>):</p><blockquote><p data-raw='“Words, since they are the nodal points of numerous ideas [“Vorstellungen” in the original], may be regarded as predestined to ambiguity; and the neuroses (e.g. in framing obsessions and phobias), no less than dreams, make unashamed use of the advantages thus offered by words for purposes of condensation and disguise.” (Freud 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR14" title="Freud S (1942) Gesammelte Werke: zweiter und dritter Band. Die Traumdeutung: Über den Traum (A. Freud, Ed.). S. Fischer">1942</a>, p. 346)'>“Words, since they are the nodal points of numerous ideas [“Vorstellungen” in the original], may be regarded as predestined to ambiguity; and the neuroses (e.g. in framing obsessions and phobias), no less than dreams, make unashamed use of the advantages thus offered by words for purposes of condensation and disguise.” (Freud
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR14 title="Freud S (1942) Gesammelte Werke: zweiter und dritter Band. Die Traumdeutung: Über den Traum (A. Freud, Ed.). S. Fischer">1942</a>, p. 346)</p></blockquote><p data-raw='The proposed reading, then, is not to interpret the mathematical core of the model metaphorically, but to recognize that the mathematical formal structure used by LLMs actively mirrors the formal structure of metaphorical and metonymical links found in human cognition. This is one of the central elements that the analysis of metaphor, whether by Blumenberg or Lacan, has focused on: that metaphorical thinking is not “less” logical, but rather follows rules and forms and can be properly formalized. What LLM research and development is doing is such a formalization, but without an awareness of the theoretical literature that has further explored this understanding of language, which adds to the black box character of LLMs.'>The proposed reading, then, is not to interpret the mathematical core of the model metaphorically, but to recognize that the mathematical formal structure used by LLMs actively mirrors the formal structure of metaphorical and metonymical links found in human cognition. This is one of the central elements that the analysis of metaphor, whether by Blumenberg or Lacan, has focused on: that metaphorical thinking is not “less” logical, but rather follows rules and forms and can be properly formalized. What LLM research and development is doing is such a formalization, but without an awareness of the theoretical literature that has further explored this understanding of language, which adds to the black box character of LLMs.</p><p data-raw='But one could still argue that LLMs do not “understand” language, but simply process it based on prior patterns. The assumption that the formal structure we find in human metaphorical reasoning is accessed only as a form of “understanding” may be one of the most common mistakes in language analysis. Understanding is commonly defined as a contextual form of reasoning, where I refer primarily to the meaning and content of a cultural context, something one could argue that LLMs excel at without any subjective understanding. Accordingly, the formal link between words, where I can either replace them metonymically with words from the same field of meaning, or the metaphorical operation that links a word to another field of meaning, both do not require understanding in the sense of experience and existential grounding, since I can easily mathematize this link, for example by a multidimensional vector that represents the metonymical (i.e. contextual) links. It is unproblematic to remove any form of content or meaning from these processes and to view them in a fully logico-mathematical form. This strongly reflects how LLMs relate tokens, which are also contextually linked through their representations in the embeddings. This is not surprising, however, since mathematics is not something radically different from language, but a specific abstracted faculty of language, which is formal, reduced, symbolic reasoning that does not work on the basis of existential understanding, but purely on the basis of formal relational rules.'>But one could still argue that LLMs do not “understand” language, but simply process it based on prior patterns. The assumption that the formal structure we find in human metaphorical reasoning is accessed only as a form of “understanding” may be one of the most common mistakes in language analysis. Understanding is commonly defined as a contextual form of reasoning, where I refer primarily to the meaning and content of a cultural context, something one could argue that LLMs excel at without any subjective understanding. Accordingly, the formal link between words, where I can either replace them metonymically with words from the same field of meaning, or the metaphorical operation that links a word to another field of meaning, both do not require understanding in the sense of experience and existential grounding, since I can easily mathematize this link, for example by a multidimensional vector that represents the metonymical (i.e. contextual) links. It is unproblematic to remove any form of content or meaning from these processes and to view them in a fully logico-mathematical form. This strongly reflects how LLMs relate tokens, which are also contextually linked through their representations in the embeddings. This is not surprising, however, since mathematics is not something radically different from language, but a specific abstracted faculty of language, which is formal, reduced, symbolic reasoning that does not work on the basis of existential understanding, but purely on the basis of formal relational rules.</p><p data-raw='Accordingly, the continental tradition, especially in the thinkers from whom this line of thought originated, Freud and Heidegger, holds that logical rules do not begin with the predicative sentence, but with the pre-predicative field of the word (Heidegger 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR19" title="Heidegger M (1976) Gesamtausgabe: vol. 21. Logik: Die Frage nach der Wahrheit. Vittorio Klostermann">1976</a>, pp. 144–148). Thus, in the context of LLMs and the metaphorical link in language, the argument is that these models, through the use of algorithms, partially reflect the formal rules of language (and, by extension, thought) without their designers necessarily being aware of this.'>Accordingly, the continental tradition, especially in the thinkers from whom this line of thought originated, Freud and Heidegger, holds that logical rules do not begin with the predicative sentence, but with the pre-predicative field of the word (Heidegger
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR19 title="Heidegger M (1976) Gesamtausgabe: vol. 21. Logik: Die Frage nach der Wahrheit. Vittorio Klostermann">1976</a>, pp. 144–148). Thus, in the context of LLMs and the metaphorical link in language, the argument is that these models, through the use of algorithms, partially reflect the formal rules of language (and, by extension, thought) without their designers necessarily being aware of this.</p><h3 id=21-metaphors-and-the-user>2.1 Metaphors and the user
<a class=anchor href=#21-metaphors-and-the-user>#</a></h3><p data-raw='An additional importance of metaphorical reasoning, i.e. the ability to link different domains of relational metonymic structures, lies in the attention mechanism. It could be argued that the model stored in the embeddings of an LLM is primarily metonymic, since the training data as such is contextual information, but this alone does not explain the impressive abilities of LLMs to approach a much wider range of problems than those covered by the training data. When responding to a prompt, LLMs decompose input strings into tokens and transform them into vector forms that encapsulate both the meaning and the context of each token. This multidimensional vector is what we have compared to the formal structure of the metaphorical and metonymical core of language. However, the metaphorical capabilities only come to the fore when we consider the way the model interacts with prompts. In addition to the contextual information gathered in training, the position of each word within the prompt is encoded, which is crucial for informing the model about the word order in the sequence. After this initial embedding, the self-attention layer allows the LLM to interpret the sentence from different directions, emphasizing different words as needed (see Vaswani et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43" title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>, pp. 5–6). This is critical because it allows the model not only to connect words that are not connected as a pattern in the training data, but also to connect different contextual patterns by connecting words, and thus their contextual data, to each other. For a deeper understanding, Brunner et al. (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR49" title="Brunner G, Liu Y, Pascual D, Richter O, Ciaramita M, Wattenhofer R (2020) On identifiability in transformers. 
https://doi.org/10.48550/arXiv.1908.04211
">2020</a>) in their paper “On Identifiability in Transformers” provide insights into how transformers, through their layered attention mechanisms, can not only capture but also amplify subtle relationships within the data. This ability to amplify is critical to understanding how LLMs can exhibit emergent abilities, including metaphorical reasoning, by reinterpreting the relationships between vectors based on the dynamic context provided by prompts.'>An additional importance of metaphorical reasoning, i.e. the ability to link different domains of relational metonymic structures, lies in the attention mechanism. It could be argued that the model stored in the embeddings of an LLM is primarily metonymic, since the training data as such is contextual information, but this alone does not explain the impressive abilities of LLMs to approach a much wider range of problems than those covered by the training data. When responding to a prompt, LLMs decompose input strings into tokens and transform them into vector forms that encapsulate both the meaning and the context of each token. This multidimensional vector is what we have compared to the formal structure of the metaphorical and metonymical core of language. However, the metaphorical capabilities only come to the fore when we consider the way the model interacts with prompts. In addition to the contextual information gathered in training, the position of each word within the prompt is encoded, which is crucial for informing the model about the word order in the sequence. After this initial embedding, the self-attention layer allows the LLM to interpret the sentence from different directions, emphasizing different words as needed (see Vaswani et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR43 title="Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.1706.03762
">2017</a>, pp. 5–6). This is critical because it allows the model not only to connect words that are not connected as a pattern in the training data, but also to connect different contextual patterns by connecting words, and thus their contextual data, to each other. For a deeper understanding, Brunner et al. (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR49 title="Brunner G, Liu Y, Pascual D, Richter O, Ciaramita M, Wattenhofer R (2020) On identifiability in transformers. 
https://doi.org/10.48550/arXiv.1908.04211
">2020</a>) in their paper “On Identifiability in Transformers” provide insights into how transformers, through their layered attention mechanisms, can not only capture but also amplify subtle relationships within the data. This ability to amplify is critical to understanding how LLMs can exhibit emergent abilities, including metaphorical reasoning, by reinterpreting the relationships between vectors based on the dynamic context provided by prompts.</p><p data-raw='These token vectors then pass through several layers of self-attention within the model. At each layer, attention scores are derived for each token based on its connections to the other tokens in the sequence. These scores adjust the vector weights, allowing the model to prioritize relevant tokens for each sequence position. This design allows the LLM to go beyond a simple metonymic or contextual understanding of a token, as this weighting can dynamically expand and shift (within a concrete dialogue) the embedded information, i.e. the knowledge the model has about the contextual information of words. This allows for nuanced relationships between vectors representing word- and association-based information, in particular allowing for new metaphorical connections by using tokens as metaphors that introduce not only the specific word into a context, but also the contextual information that word carries, mirroring Freud’s explanation of the link established by the word cocaine in his interpretation of dreams:'>These token vectors then pass through several layers of self-attention within the model. At each layer, attention scores are derived for each token based on its connections to the other tokens in the sequence. These scores adjust the vector weights, allowing the model to prioritize relevant tokens for each sequence position. This design allows the LLM to go beyond a simple metonymic or contextual understanding of a token, as this weighting can dynamically expand and shift (within a concrete dialogue) the embedded information, i.e. the knowledge the model has about the contextual information of words. This allows for nuanced relationships between vectors representing word- and association-based information, in particular allowing for new metaphorical connections by using tokens as metaphors that introduce not only the specific word into a context, but also the contextual information that word carries, mirroring Freud’s explanation of the link established by the word cocaine in his interpretation of dreams:</p><blockquote><p data-raw='“A further set of connections was then established—those surrounding the idea of cocaine, which had every right to serve as a link between the figure of Dr. Königstein and a botanical monograph which I had written; and these connections strengthened the fusion between the two groups of ideas [Vorstellungskreise in the original] so that it became possible for a portion of the one experience to serve as an allusion to the other one.” (Freud 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR13" title="Freud S (2010) The interpretation of dreams. Basic Books">2010</a>, p. 199)'>“A further set of connections was then established—those surrounding the idea of cocaine, which had every right to serve as a link between the figure of Dr. Königstein and a botanical monograph which I had written; and these connections strengthened the fusion between the two groups of ideas [Vorstellungskreise in the original] so that it became possible for a portion of the one experience to serve as an allusion to the other one.” (Freud
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR13 title="Freud S (2010) The interpretation of dreams. Basic Books">2010</a>, p. 199)</p></blockquote><p data-raw='This allows the model not only to generate weightings that are not based on its training data, but also to connect otherwise disparate patterns of tokens, much as Freud is able to connect a person’s circles of representation through the signifier “cocaine” with a botanical monograph. The ability to do this, however, lies not in its training data, but in its attention mechanism reading the prompt. While the LLM’s knowledge and response generation is based on patterns in its training data, the combination and application of this knowledge in novel contexts, as prompted by the user, can therefore lead to unique outputs that are not direct “replicas” of its training examples. It is this mechanism of transformer models that allows them to produce such lifelike responses, but also creates unique forms of error in the form of hallucinations. Since LLMs only have access to the symbolic, in Freudian terms, the generalized word associations in the embedding layers, human–machine interaction allows the user to alter and twist this symbolic web of associations based on their individual socialization and learning. This happens unconsciously, if one is not aware of how much prompting influences the LLM, so it is central to understand the human-technology interaction that takes place here.'>This allows the model not only to generate weightings that are not based on its training data, but also to connect otherwise disparate patterns of tokens, much as Freud is able to connect a person’s circles of representation through the signifier “cocaine” with a botanical monograph. The ability to do this, however, lies not in its training data, but in its attention mechanism reading the prompt. While the LLM’s knowledge and response generation is based on patterns in its training data, the combination and application of this knowledge in novel contexts, as prompted by the user, can therefore lead to unique outputs that are not direct “replicas” of its training examples. It is this mechanism of transformer models that allows them to produce such lifelike responses, but also creates unique forms of error in the form of hallucinations. Since LLMs only have access to the symbolic, in Freudian terms, the generalized word associations in the embedding layers, human–machine interaction allows the user to alter and twist this symbolic web of associations based on their individual socialization and learning. This happens unconsciously, if one is not aware of how much prompting influences the LLM, so it is central to understand the human-technology interaction that takes place here.</p><p data-raw='This also means that there is a direct application of looking at prompting through the lens of metaphor and metonymy. The current concept of “prompt engineering” as a seemingly technical approach might be much better approached as “prompt prose,” since even small shifts in metonymic substitution or metaphoric linkage can dramatically alter the quality of a produced output (Ekin 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR10" title="Ekin S (2023) Prompt engineering for ChatGPT: a quick guide to techniques, tips, and best practices. Advance online publication. 
https://doi.org/10.36227/techrxiv.22683919.v2
">2023</a>; Wei et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR44" title="Wei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, Chi E, Le Q, Zhou D (2022) Chain-of-thought prompting elicits reasoning in large language models. In: 36th Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.2201.11903
">2022</a>; White et al. 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR45" title="White J, Fu Q, Hays S, Sandborn M, Olea C, Gilbert H, Elnashar A, Spencer-Smith J, Schmidt DC (2023) A prompt pattern catalog to enhance prompt engineering with ChatGPT. Advance online publication. 
https://doi.org/10.48550/arXiv.2302.11382
">2023</a>). Thus, approaching prompt problems with the technical idea of a clear and unambiguous technical definition may overshadow the poetic dimension that the model here requires to produce the best output. But to fully understand the limitations of this human–AI interaction, we need to be aware of the inherent limitations it creates.'>This also means that there is a direct application of looking at prompting through the lens of metaphor and metonymy. The current concept of “prompt engineering” as a seemingly technical approach might be much better approached as “prompt prose,” since even small shifts in metonymic substitution or metaphoric linkage can dramatically alter the quality of a produced output (Ekin
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR10 title="Ekin S (2023) Prompt engineering for ChatGPT: a quick guide to techniques, tips, and best practices. Advance online publication. 
https://doi.org/10.36227/techrxiv.22683919.v2
">2023</a>; Wei et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR44 title="Wei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, Chi E, Le Q, Zhou D (2022) Chain-of-thought prompting elicits reasoning in large language models. In: 36th Conference on Neural Information Processing Systems. Advance online publication. 
https://doi.org/10.48550/arXiv.2201.11903
">2022</a>; White et al.
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR45 title="White J, Fu Q, Hays S, Sandborn M, Olea C, Gilbert H, Elnashar A, Spencer-Smith J, Schmidt DC (2023) A prompt pattern catalog to enhance prompt engineering with ChatGPT. Advance online publication. 
https://doi.org/10.48550/arXiv.2302.11382
">2023</a>). Thus, approaching prompt problems with the technical idea of a clear and unambiguous technical definition may overshadow the poetic dimension that the model here requires to produce the best output. But to fully understand the limitations of this human–AI interaction, we need to be aware of the inherent limitations it creates.</p><h2 id=3-metaphors-and-the-void>3 Metaphors and the void
<a class=anchor href=#3-metaphors-and-the-void>#</a></h2><p data-raw='We can either conceptualize these structures of metaphoric and metonymic connection as ‘systematic’, structured by a fundamental unity or coherence, as any computer necessarily does, or we can assume, and this is where continental philosophy differs strongly from analytic discourse [with some exceptions like Graham Priest (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR39" title="Priest G (2006) In contradiction: a study of the transconsistent, Expanded. Clarendon Press">2006</a>)], that it is fundamentally bound to the void, following the radical philosophical critique of systems that followed Nietzsche. This assumes that these structures of connection are always already fragmented, discontinuous, and even contradictory. This notion can be found in thinkers such as Derrida, who emphasizes the play of differences and displacements in language, or in Lacan’s assertion that “there is no meta-language” (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR27" title="Lacan J (2002) The seminar of Jacques Lacan XIII: the object of psychoanalysis. The Seminar of Jacques Lacan (Lacan in Ireland). Karnac Books">2002</a>, 8.12.1965), emphasizing the irreducible gap or lack in any symbolic system. In the context of LLMs such as GPT, the “systematic” approach holds true in terms of how these models are designed and trained, but when deployed in real-world scenarios, i.e., when confronted with user prompts that represent a connection not found in the training data, they may inadvertently replicate and run afoul of the gaps, inconsistencies, and discontinuities found in human language and cognition.'>We can either conceptualize these structures of metaphoric and metonymic connection as ‘systematic’, structured by a fundamental unity or coherence, as any computer necessarily does, or we can assume, and this is where continental philosophy differs strongly from analytic discourse [with some exceptions like Graham Priest (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR39 title="Priest G (2006) In contradiction: a study of the transconsistent, Expanded. Clarendon Press">2006</a>)], that it is fundamentally bound to the void, following the radical philosophical critique of systems that followed Nietzsche. This assumes that these structures of connection are always already fragmented, discontinuous, and even contradictory. This notion can be found in thinkers such as Derrida, who emphasizes the play of differences and displacements in language, or in Lacan’s assertion that “there is no meta-language” (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR27 title="Lacan J (2002) The seminar of Jacques Lacan XIII: the object of psychoanalysis. The Seminar of Jacques Lacan (Lacan in Ireland). Karnac Books">2002</a>, 8.12.1965), emphasizing the irreducible gap or lack in any symbolic system. In the context of LLMs such as GPT, the “systematic” approach holds true in terms of how these models are designed and trained, but when deployed in real-world scenarios, i.e., when confronted with user prompts that represent a connection not found in the training data, they may inadvertently replicate and run afoul of the gaps, inconsistencies, and discontinuities found in human language and cognition.</p><p data-raw='As we have argued, both metaphor and metonymy are represented in the mathematical models of LLMs, with metaphor playing a particularly crucial role because of its structural importance and its relationship to the concept of void, or what Blumenberg calls “absolute metaphors”. Understanding what an absolute metaphor is, its relationship to the void and systemic thought, and its relevance to LLMs is essential. Heidegger was among the first to discuss the profound impact of central metaphorical structures on our comprehensive worldview. He posited that “being” is shaped by specific perspectives that are structured and organized by primordial words, similar to the Greek ϕύσις (Heidegger 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR20" title="Heidegger M (1984) Gesamtausgabe: vol. 45. Grundfragen der Philosophie: Ausgewählte »Probleme« der »Logik« (F.-W. von Hermann, Ed.). Vittorio Klostermann">1984</a>, p. 131), which frame our epistemic and practical relationships to entities. These foundational words are invariably related to the void, which serves as the foundation of symbolic systems, and are related to Heidegger’s concept of “Ab-Grund” or “abyssal ground”. This term denotes the fundamental absence of an ontological foundation, which paradoxically functions as a foundation itself. For Heidegger, such metaphorical anchors that delineate our profound perspectives were exceptional, forming essential distinctions that underpin metaphysical and logical premises. They are essential to a pre-predicative system of language, structured primarily by the “as” relation between words (Heidegger 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR21" title="Heidegger M (1996) SUNY series in contemporary continental philosophy. Being and time: a translation of Sein und Zeit (J. Stambaugh, Trans.). State University of New York Press">1996</a>, p. 139), that emerges from practice.'>As we have argued, both metaphor and metonymy are represented in the mathematical models of LLMs, with metaphor playing a particularly crucial role because of its structural importance and its relationship to the concept of void, or what Blumenberg calls “absolute metaphors”. Understanding what an absolute metaphor is, its relationship to the void and systemic thought, and its relevance to LLMs is essential. Heidegger was among the first to discuss the profound impact of central metaphorical structures on our comprehensive worldview. He posited that “being” is shaped by specific perspectives that are structured and organized by primordial words, similar to the Greek ϕύσις (Heidegger
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR20 title="Heidegger M (1984) Gesamtausgabe: vol. 45. Grundfragen der Philosophie: Ausgewählte »Probleme« der »Logik« (F.-W. von Hermann, Ed.). Vittorio Klostermann">1984</a>, p. 131), which frame our epistemic and practical relationships to entities. These foundational words are invariably related to the void, which serves as the foundation of symbolic systems, and are related to Heidegger’s concept of “Ab-Grund” or “abyssal ground”. This term denotes the fundamental absence of an ontological foundation, which paradoxically functions as a foundation itself. For Heidegger, such metaphorical anchors that delineate our profound perspectives were exceptional, forming essential distinctions that underpin metaphysical and logical premises. They are essential to a pre-predicative system of language, structured primarily by the “as” relation between words (Heidegger
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR21 title="Heidegger M (1996) SUNY series in contemporary continental philosophy. Being and time: a translation of Sein und Zeit (J. Stambaugh, Trans.). State University of New York Press">1996</a>, p. 139), that emerges from practice.</p><p data-raw='Blumenberg expanded on this foundation in 1960 by defining “absolute metaphors” as metaphors that refer to something unknown and indeterminate, which I must assume to be a formal element of determination. He argued, “Absolute metaphors ‘answer’ the seemingly naive, fundamentally unanswerable questions that are intrinsic to our existence, questions we find already set before us rather than ones we pose” (Blumenberg and Savage 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR3" title="Blumenberg H, Savage RI (2010) Paradigms for a metaphorology. Signale. Cornell University Press">2010</a>, p. 14). Normal metaphors and absolute metaphors differ in their depth of integration into conceptual frameworks and their interchangeability. Normal metaphors are tools of language that we use to make comparisons or to illustrate and explain one thing in terms of another, often in a particular context or for a particular effect. They are relatively flexible and can be replaced or interchanged without significantly altering the underlying meaning or understanding of the concept they describe. Absolute metaphors, on the other hand, are deeply embedded in our conceptual and perceptual frameworks. They are fundamental to our understanding of complex or abstract domains and make those domains accessible to human thought and language. Absolute metaphors cannot be replaced by literal language or other metaphors without losing essential aspects of meaning, because they organize theoretical frameworks by enabling associative patterns that are otherwise inaccessible. Similarly, Lacan’s notion of the “master signifier,” which mirrors Blumenberg’s absolute metaphor although there is no direct dialogue between the two, structures the complex dynamics between the individual and society. It represents a more localized form of conceptualization compared to Heidegger’s broader modes of being. These two metaphorical frameworks thus not only provide a scaffold for understanding the world, but also problematize that understanding by resisting simplification into definitive concepts. This highlights the role of metaphor in shaping our language, thought, and engagement with reality, rather than constituting the core of a philosophical epoch.'>Blumenberg expanded on this foundation in 1960 by defining “absolute metaphors” as metaphors that refer to something unknown and indeterminate, which I must assume to be a formal element of determination. He argued, “Absolute metaphors ‘answer’ the seemingly naive, fundamentally unanswerable questions that are intrinsic to our existence, questions we find already set before us rather than ones we pose” (Blumenberg and Savage
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR3 title="Blumenberg H, Savage RI (2010) Paradigms for a metaphorology. Signale. Cornell University Press">2010</a>, p. 14). Normal metaphors and absolute metaphors differ in their depth of integration into conceptual frameworks and their interchangeability. Normal metaphors are tools of language that we use to make comparisons or to illustrate and explain one thing in terms of another, often in a particular context or for a particular effect. They are relatively flexible and can be replaced or interchanged without significantly altering the underlying meaning or understanding of the concept they describe. Absolute metaphors, on the other hand, are deeply embedded in our conceptual and perceptual frameworks. They are fundamental to our understanding of complex or abstract domains and make those domains accessible to human thought and language. Absolute metaphors cannot be replaced by literal language or other metaphors without losing essential aspects of meaning, because they organize theoretical frameworks by enabling associative patterns that are otherwise inaccessible. Similarly, Lacan’s notion of the “master signifier,” which mirrors Blumenberg’s absolute metaphor although there is no direct dialogue between the two, structures the complex dynamics between the individual and society. It represents a more localized form of conceptualization compared to Heidegger’s broader modes of being. These two metaphorical frameworks thus not only provide a scaffold for understanding the world, but also problematize that understanding by resisting simplification into definitive concepts. This highlights the role of metaphor in shaping our language, thought, and engagement with reality, rather than constituting the core of a philosophical epoch.</p><p data-raw='All of these concepts share a central element: their intimate relationship to the void. For Blumenberg, this means that these central metaphorical structures refer to and obscure existential questions, but questions that are unanswerable and necessary to the formal systems of thought in which they appear. A “relation to the void” in this sense is therefore an absence of meaning, an absence of a definite answer to the question of what is being voided. The void, then, is not indeterminacy as something probabilistic, but indeterminacy as something undeterminable that terminates an associative chain of signifiers. Here the continental (Lacanian) tradition of logic separates itself from the analytic tradition by assuming that a scientific formal system is marked by “the real [as] the impasse of formalization” (Badiou 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1" title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, p. 5). That is, the master signifiers or absolute metaphors that we can discern in human language use are not marked by a contradictory or antinomic conceptualization, but they mark specific points of impasse where the formal system itself relies on these impasses as such. In the architecture of the LLM, however, such endpoints of associative links do not exist structurally; instead, it necessarily constructs a system, a set of links that constitute the final state of its training.'>All of these concepts share a central element: their intimate relationship to the void. For Blumenberg, this means that these central metaphorical structures refer to and obscure existential questions, but questions that are unanswerable and necessary to the formal systems of thought in which they appear. A “relation to the void” in this sense is therefore an absence of meaning, an absence of a definite answer to the question of what is being voided. The void, then, is not indeterminacy as something probabilistic, but indeterminacy as something undeterminable that terminates an associative chain of signifiers. Here the continental (Lacanian) tradition of logic separates itself from the analytic tradition by assuming that a scientific formal system is marked by “the real [as] the impasse of formalization” (Badiou
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1 title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, p. 5). That is, the master signifiers or absolute metaphors that we can discern in human language use are not marked by a contradictory or antinomic conceptualization, but they mark specific points of impasse where the formal system itself relies on these impasses as such. In the architecture of the LLM, however, such endpoints of associative links do not exist structurally; instead, it necessarily constructs a system, a set of links that constitute the final state of its training.</p><p data-raw='This is best illustrated by a direct comparison between Aristotle’s interpretation of predicative logic and Lacan’s logic of the pas-tout. The key to understanding the difference lies in how we perceive universality in predicate calculus and in Lacan’s logic. In standard logic, universality is clear; if something is universally true, it applies to all members of a set without exception. In Lacan’s logical framework, particularly with the “pas-tout” logic of female sexuality, universality is inherently disrupted. The “not all” implies that while some members of the set may adhere to a statement, there is always an elusive portion that does not, and that portion cannot be pinpointed or specified. The reason for this has been articulated by Badiou as a variant of Nietsche’s “God is dead”: the One, the encompassing universality, does not exist, which is unprovable but as much a fundamental assumption as its theological opposite (Badiou 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1" title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, pp. 23–25). While this foundational position of the non-all cannot be determined from a functioning system, it can even be shown to be necessary, as Badiou has done (Badiou 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1" title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, pp. 81–101). This has profound implications for a wide range of disciplines, including AI research, because, to put it in Lacanian terms, the system’s axiom of wholeness is an imaginary mirage. However, this imaginary mirage is not just a kind of fallacy specific to systematic thought but is instead deeply dependent on the use of metaphorical structure itself, which acts as a limiter on metonymic knowledge and thus makes it appear “whole”. This means that philosophical logic, as discussed by Heidegger, Lacan, and more recently Badiou and Žižek, is structured by an inherent connection of the symbolic, i.e. logico-mathematical form, to the void (Badiou 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1" title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, pp. 55–59) or to the less-than-nothing for which “nothing” is a signifier (Žižek 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR46" title="Žižek S (2012) Less than nothing. Hegel and the shadow of dialectical materialism. Verso">2012</a>, pp. 60–69). Now, within a hallucination as discussed above, we can already see how an LLM circles its lack of knowledge and through this movement creates a formal structure of knowledge without knowing about this lack.'>This is best illustrated by a direct comparison between Aristotle’s interpretation of predicative logic and Lacan’s logic of the pas-tout. The key to understanding the difference lies in how we perceive universality in predicate calculus and in Lacan’s logic. In standard logic, universality is clear; if something is universally true, it applies to all members of a set without exception. In Lacan’s logical framework, particularly with the “pas-tout” logic of female sexuality, universality is inherently disrupted. The “not all” implies that while some members of the set may adhere to a statement, there is always an elusive portion that does not, and that portion cannot be pinpointed or specified. The reason for this has been articulated by Badiou as a variant of Nietsche’s “God is dead”: the One, the encompassing universality, does not exist, which is unprovable but as much a fundamental assumption as its theological opposite (Badiou
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1 title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, pp. 23–25). While this foundational position of the non-all cannot be determined from a functioning system, it can even be shown to be necessary, as Badiou has done (Badiou
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1 title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, pp. 81–101). This has profound implications for a wide range of disciplines, including AI research, because, to put it in Lacanian terms, the system’s axiom of wholeness is an imaginary mirage. However, this imaginary mirage is not just a kind of fallacy specific to systematic thought but is instead deeply dependent on the use of metaphorical structure itself, which acts as a limiter on metonymic knowledge and thus makes it appear “whole”. This means that philosophical logic, as discussed by Heidegger, Lacan, and more recently Badiou and Žižek, is structured by an inherent connection of the symbolic, i.e. logico-mathematical form, to the void (Badiou
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR1 title="Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum">2006</a>, pp. 55–59) or to the less-than-nothing for which “nothing” is a signifier (Žižek
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR46 title="Žižek S (2012) Less than nothing. Hegel and the shadow of dialectical materialism. Verso">2012</a>, pp. 60–69). Now, within a hallucination as discussed above, we can already see how an LLM circles its lack of knowledge and through this movement creates a formal structure of knowledge without knowing about this lack.</p><p data-raw='The point here is that the formal function of an absolute metaphor can be easily demonstrated in an LLM because of its systematicity, i.e. its closed system of associative links, which can be confronted with a prompt indicating knowledge outside this system. If there are associative patterns that allow the conceptualization of this outside, the response of the model can be, for example, the indication of a knowledge cut-off. In this case, the model was able to relate the information provided in the prompt to its own knowledge of time and could, therefore, match it with the strongly weighted pattern of the knowledge cut-off. When, as in the Capo Ferro example, the model has little knowledge of its lack of knowledge, the prompt and attention mechanisms force the model to create new associative patterns, which are created by overlapping word associations stored in the model, thus creating a temporary new pattern that organizes the response. This can be as simple as linking two words that are normally unlikely to occur together, as it creates a new link that will create pattern-like strong associative links between the associative fields in which these words are known, which are not training based but prompt based. However, since these new patterns do not persist, they are not absolute metaphors in Blumenberg’s strict sense, but rather temporary ones. But they still share the central aspect of Blumenberg’s absolute metaphors, that their function is based on this lack of knowledge, rather than on the normal superimposition of one associative pattern on another, where this superimposition can be removed without losing the information represented. In the case of a prompt generated pattern based on a lack of knowledge or a temporary absolute metaphor, the ability of the LLM to associate two or more patterns of its knowledge base without the metaphorical link created by the prompt disappears.'>The point here is that the formal function of an absolute metaphor can be easily demonstrated in an LLM because of its systematicity, i.e. its closed system of associative links, which can be confronted with a prompt indicating knowledge outside this system. If there are associative patterns that allow the conceptualization of this outside, the response of the model can be, for example, the indication of a knowledge cut-off. In this case, the model was able to relate the information provided in the prompt to its own knowledge of time and could, therefore, match it with the strongly weighted pattern of the knowledge cut-off. When, as in the Capo Ferro example, the model has little knowledge of its lack of knowledge, the prompt and attention mechanisms force the model to create new associative patterns, which are created by overlapping word associations stored in the model, thus creating a temporary new pattern that organizes the response. This can be as simple as linking two words that are normally unlikely to occur together, as it creates a new link that will create pattern-like strong associative links between the associative fields in which these words are known, which are not training based but prompt based. However, since these new patterns do not persist, they are not absolute metaphors in Blumenberg’s strict sense, but rather temporary ones. But they still share the central aspect of Blumenberg’s absolute metaphors, that their function is based on this lack of knowledge, rather than on the normal superimposition of one associative pattern on another, where this superimposition can be removed without losing the information represented. In the case of a prompt generated pattern based on a lack of knowledge or a temporary absolute metaphor, the ability of the LLM to associate two or more patterns of its knowledge base without the metaphorical link created by the prompt disappears.</p><p data-raw='On the other hand, while these temporary absolute metaphors created by the prompt of an LLM may be easy to show, they imply the existence of true absolute metaphors within the training data of LLMs. That is, the weighting structures within the training data are oriented around the voids of meaning that existed in the data used to train an LLM. LLMs are trained on large datasets of human language, which, if we follow Blumenberg, will inevitably contain traces of absolute metaphors. The model learns patterns and relationships between words, including those structured by absolute metaphors. However, LLMs have no ability to process the lack by which these metaphors are structured; they simply reproduce the patterns ordered by the metaphor. This is manifested in their structural and formal inability to “know what it doesn’t know”. In this sense, when an LLM encounters a question or prompt that touches an area of this void, it does its best to generate a coherent response based on the closest patterns it recognizes from its training.'>On the other hand, while these temporary absolute metaphors created by the prompt of an LLM may be easy to show, they imply the existence of true absolute metaphors within the training data of LLMs. That is, the weighting structures within the training data are oriented around the voids of meaning that existed in the data used to train an LLM. LLMs are trained on large datasets of human language, which, if we follow Blumenberg, will inevitably contain traces of absolute metaphors. The model learns patterns and relationships between words, including those structured by absolute metaphors. However, LLMs have no ability to process the lack by which these metaphors are structured; they simply reproduce the patterns ordered by the metaphor. This is manifested in their structural and formal inability to “know what it doesn’t know”. In this sense, when an LLM encounters a question or prompt that touches an area of this void, it does its best to generate a coherent response based on the closest patterns it recognizes from its training.</p><p data-raw='One of the central elements of both Heidegger’s and Blumenberg’s analysis of these central metaphors is that, once seen for what they are, they falter as structural building blocks of the systems they seem to support, as Heidegger aims to transcend the metaphorically grounded “forgetfulness of being” and Blumenberg argues that we can no longer rely on metaphorical thinking today. In this sense, both Heidegger and Blumenberg follow a classical rationalist notion of coherence. But this is not the case with Lacan. Following Freud, Lacan is aware that it does not matter whether a master signifier has been consciously rejected, as long as it structures the unconscious. Following the radical conclusion of the critique of systems, Lacan cannot propose to replace the void-based structure of a central metaphorical unity with a more comprehensive unity, but rather assumes that there is a permanent and shifting deadlock in any system of thought. A subject orienting itself within such a symbolic order must therefore somehow integrate these deadlocks into its symbolic order as deadlocks. For Lacan, there are different modes of subjectivity in which humans approach this central lack in our systems of thought, and current LLMs operate on an architecture that inadvertently mimics foreclosure.'>One of the central elements of both Heidegger’s and Blumenberg’s analysis of these central metaphors is that, once seen for what they are, they falter as structural building blocks of the systems they seem to support, as Heidegger aims to transcend the metaphorically grounded “forgetfulness of being” and Blumenberg argues that we can no longer rely on metaphorical thinking today. In this sense, both Heidegger and Blumenberg follow a classical rationalist notion of coherence. But this is not the case with Lacan. Following Freud, Lacan is aware that it does not matter whether a master signifier has been consciously rejected, as long as it structures the unconscious. Following the radical conclusion of the critique of systems, Lacan cannot propose to replace the void-based structure of a central metaphorical unity with a more comprehensive unity, but rather assumes that there is a permanent and shifting deadlock in any system of thought. A subject orienting itself within such a symbolic order must therefore somehow integrate these deadlocks into its symbolic order as deadlocks. For Lacan, there are different modes of subjectivity in which humans approach this central lack in our systems of thought, and current LLMs operate on an architecture that inadvertently mimics foreclosure.</p><h2 id=4-foreclosure-in-llms>4 Foreclosure in LLMs
<a class=anchor href=#4-foreclosure-in-llms>#</a></h2><p data-raw='This thesis that the current generation of LLMs is structurally affected by a foreclosure that mimics the psychotic subject may seem an absurd anthropomorphism, but the absurdity of this statement lies solely in the assumption that psychosis is primarily an exceptional pathological event rather than a specific subjectivation of the symbolic structures we use to make sense of the world. As noted above, by focusing on the logical structures of cognition rather than on secondary phenomena (i.e., those ordered by our logical structures), clinical psychoanalysts following Lacan have found, first, that psychosis has an ordinary form, that is, an appearance that does not primarily correspond to the idea of a raving mad subject (Miller 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR35" title="Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytical Notebooks: Symptoms (Vol 7)">2002</a>), and, second, that this ordinary form is a specific form of subjectivation of the subject’s relationship to the constitutive voids of our symbolic and formal structures of thought. This means approaching psychosis as structured by “language and logic” (Leader 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30" title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, pp. 95–114) rather than its possible genetic or neurochemical origins. Lacanian psychoanalysis thus moves towards a structural and mathematical representation of the subject. This also allows us to approach computation with the tools developed by Lacanian psychoanalysis, since we analyze only the structural makeup of LLMs’ use and representation of language and logic.'>This thesis that the current generation of LLMs is structurally affected by a foreclosure that mimics the psychotic subject may seem an absurd anthropomorphism, but the absurdity of this statement lies solely in the assumption that psychosis is primarily an exceptional pathological event rather than a specific subjectivation of the symbolic structures we use to make sense of the world. As noted above, by focusing on the logical structures of cognition rather than on secondary phenomena (i.e., those ordered by our logical structures), clinical psychoanalysts following Lacan have found, first, that psychosis has an ordinary form, that is, an appearance that does not primarily correspond to the idea of a raving mad subject (Miller
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR35 title="Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytical Notebooks: Symptoms (Vol 7)">2002</a>), and, second, that this ordinary form is a specific form of subjectivation of the subject’s relationship to the constitutive voids of our symbolic and formal structures of thought. This means approaching psychosis as structured by “language and logic” (Leader
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30 title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, pp. 95–114) rather than its possible genetic or neurochemical origins. Lacanian psychoanalysis thus moves towards a structural and mathematical representation of the subject. This also allows us to approach computation with the tools developed by Lacanian psychoanalysis, since we analyze only the structural makeup of LLMs’ use and representation of language and logic.</p><p data-raw='What does Lacanian psychoanalysis identify as the key features of psychosis? First, it suggests that a person with psychosis is not primarily affected by the repression of the unconscious. They do not orient themselves around the necessary deadlocks of the symbolic order by using them in the form of absolute metaphors. Instead, it is dominated by the complete omission of these fundamental deadlocks, which is called “foreclosure”. Repression means that the unconscious components are still part of the person’s structural makeup or identity but are denied or negated. These negated aspects, however, have a structuring and ordering place in the person’s psyche. This is similar to the way we think about misplaced keys: they are gone, but their absence is still recognized, and their present absence structures our search for them. These “lost keys” are fundamentally an abstract object, grounded not in experience but in our capacity for abstract and negative thinking. Foreclosure, however, takes negation to an extreme. Whereas repression acknowledges the missing object through negation, foreclosure acts as if the object never existed. For Lacan, then, foreclosure and repression are different forms of negation, one producing a symbolic object that exists as negated, the other a complete voiding of the object.'>What does Lacanian psychoanalysis identify as the key features of psychosis? First, it suggests that a person with psychosis is not primarily affected by the repression of the unconscious. They do not orient themselves around the necessary deadlocks of the symbolic order by using them in the form of absolute metaphors. Instead, it is dominated by the complete omission of these fundamental deadlocks, which is called “foreclosure”. Repression means that the unconscious components are still part of the person’s structural makeup or identity but are denied or negated. These negated aspects, however, have a structuring and ordering place in the person’s psyche. This is similar to the way we think about misplaced keys: they are gone, but their absence is still recognized, and their present absence structures our search for them. These “lost keys” are fundamentally an abstract object, grounded not in experience but in our capacity for abstract and negative thinking. Foreclosure, however, takes negation to an extreme. Whereas repression acknowledges the missing object through negation, foreclosure acts as if the object never existed. For Lacan, then, foreclosure and repression are different forms of negation, one producing a symbolic object that exists as negated, the other a complete voiding of the object.</p><p data-raw='Lacan emphasized what is specifically omitted in psychosis: the master signifier, that is, a metaphorical object that acts as a specific substitute for the deadlock in the system of thought. This is the same structure that, following Blumenberg, we have called absolute metaphors. The psychotic, for whatever reason, is unable to constitute this symbolic object. Unlike the “lost keys,” which is a symbolic object (a signifier) that stands for something specific that has been lost, the master signifier stands for something that is originally lost, so to speak, that exists only as a lack, without ever existing as a positive phenomenon. Freud’s classic example of this is the lack of the almighty father (which never existed), which returns in the theological object of a monotheistic God. This signifier shapes our thought systems in the guise of the Big Other, a central concept of Lacanian psychoanalysis. In normal neurotics, our intersubjective connections aren’t just with particular others. We also connect to the “Big Other,” a broad concept of otherness that represents the language-based transcendental structure that appears to be opposite or “outside” our own identity. This great other is constructed on the basis of a negational relation, as manifested, for example, in the castrating statement “the true father is what I am not,” which constructs an ideal “the true father” and marks the subject’s inability to conform to it. These major (i.e., culturally manifested) or minor (i.e., structured by personal development) absolute metaphors structure the systematic aspect of this big Other as the structure of our transcendental framework. The subject is thus mirrored by a phantasmatic ideal and its own need to adhere to this ideal on the basis of its own lack (cf. anonymized 2022). In a broad sense, the big Other acts as a linguistic or symbolic mirror that allows us to understand or misunderstand our place in society on the basis of central metaphors that order the field of meaning. While this formal structure is easily delineated in Christian theology, where the big Other is manifested as the divine being, it also exists in other types of transcendental systems.'>Lacan emphasized what is specifically omitted in psychosis: the master signifier, that is, a metaphorical object that acts as a specific substitute for the deadlock in the system of thought. This is the same structure that, following Blumenberg, we have called absolute metaphors. The psychotic, for whatever reason, is unable to constitute this symbolic object. Unlike the “lost keys,” which is a symbolic object (a signifier) that stands for something specific that has been lost, the master signifier stands for something that is originally lost, so to speak, that exists only as a lack, without ever existing as a positive phenomenon. Freud’s classic example of this is the lack of the almighty father (which never existed), which returns in the theological object of a monotheistic God. This signifier shapes our thought systems in the guise of the Big Other, a central concept of Lacanian psychoanalysis. In normal neurotics, our intersubjective connections aren’t just with particular others. We also connect to the “Big Other,” a broad concept of otherness that represents the language-based transcendental structure that appears to be opposite or “outside” our own identity. This great other is constructed on the basis of a negational relation, as manifested, for example, in the castrating statement “the true father is what I am not,” which constructs an ideal “the true father” and marks the subject’s inability to conform to it. These major (i.e., culturally manifested) or minor (i.e., structured by personal development) absolute metaphors structure the systematic aspect of this big Other as the structure of our transcendental framework. The subject is thus mirrored by a phantasmatic ideal and its own need to adhere to this ideal on the basis of its own lack (cf. anonymized 2022). In a broad sense, the big Other acts as a linguistic or symbolic mirror that allows us to understand or misunderstand our place in society on the basis of central metaphors that order the field of meaning. While this formal structure is easily delineated in Christian theology, where the big Other is manifested as the divine being, it also exists in other types of transcendental systems.</p><p data-raw='So what does it mean that the master signifier is excluded? Lacan discussed that the big Other in psychosis is characterized by an “imaginary degradation of otherness” (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR25" title="Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company">1993</a>, p. 101). This marks a very specific form of degradation, since the term “imaginary” has a technical meaning in Lacan’s theory. The imaginary is the register of sensual receptivity, and its remarkable formal structure is that there is no absence in sensual receptivity. The “hole in the wall” that I see requires a system of meaning that tells me that the hole, a symbolic object that marks this lack, is where something positive is missing. It requires the same symbolic object that tells me my keys are missing. Imaginary degradation therefore means that the symbolic structure, which normally includes master signifiers that create the phantasy of a consistent structure by representing and occluding the void, can no longer be maintained by the psychotic subject. Its symbolic structure, which organizes its fields of meaning, becomes imaginary, i.e. it loses access to the indeterminate.'>So what does it mean that the master signifier is excluded? Lacan discussed that the big Other in psychosis is characterized by an “imaginary degradation of otherness” (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR25 title="Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company">1993</a>, p. 101). This marks a very specific form of degradation, since the term “imaginary” has a technical meaning in Lacan’s theory. The imaginary is the register of sensual receptivity, and its remarkable formal structure is that there is no absence in sensual receptivity. The “hole in the wall” that I see requires a system of meaning that tells me that the hole, a symbolic object that marks this lack, is where something positive is missing. It requires the same symbolic object that tells me my keys are missing. Imaginary degradation therefore means that the symbolic structure, which normally includes master signifiers that create the phantasy of a consistent structure by representing and occluding the void, can no longer be maintained by the psychotic subject. Its symbolic structure, which organizes its fields of meaning, becomes imaginary, i.e. it loses access to the indeterminate.</p><p data-raw='Why is this loss of symbolic substitutes for the indeterminate important? As we have indicated, both Heidegger’s and Lacan’s reading of Aristotelian logic marked a formal element of indeterminate excess that any universal statement or system produces. This excess in the form of a deadlock is not just an external element, it is a formal necessity of the universal or systematic. As Alain Badiou showed in “Being and Event”, this indeterminate excess of systematic structures is also the ground on which we construct our concrete historical formal systems of meaning as such. This leads to the world in which the psychotic finds himself by resorting to a dissection into parts of parts that only form an imaginary coherence, that is, a coherence based on the exclusion of the constitutive lack (Leader 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30" title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 130). Since this imaginary coherence must produce frustration, i.e. a dissonance between the symbolic structure of meaning and the complexity of language, which is oriented towards absolute metaphors, the psychotic subject is constantly confronted with indeterminacy, but cannot conceptualize it except as structured by an imaginary coherence.'>Why is this loss of symbolic substitutes for the indeterminate important? As we have indicated, both Heidegger’s and Lacan’s reading of Aristotelian logic marked a formal element of indeterminate excess that any universal statement or system produces. This excess in the form of a deadlock is not just an external element, it is a formal necessity of the universal or systematic. As Alain Badiou showed in “Being and Event”, this indeterminate excess of systematic structures is also the ground on which we construct our concrete historical formal systems of meaning as such. This leads to the world in which the psychotic finds himself by resorting to a dissection into parts of parts that only form an imaginary coherence, that is, a coherence based on the exclusion of the constitutive lack (Leader
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30 title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 130). Since this imaginary coherence must produce frustration, i.e. a dissonance between the symbolic structure of meaning and the complexity of language, which is oriented towards absolute metaphors, the psychotic subject is constantly confronted with indeterminacy, but cannot conceptualize it except as structured by an imaginary coherence.</p><p data-raw='Now, the effect of this exclusion of the master signifier is the psychotic’s tendency to orient his symbolic universe toward localized indeterminacy. Leader identifies this individualized (re)structuring of the world, reduced to a single moment of cognition with a strong retroactive effect, as a characteristic of the psychotic subject (Leader 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30" title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 125). Psychotic identity thus confronts the subject with a fringing multiplicity of meanings, particularized by circling around a localized indeterminate element, not unlike LLM’s hallucinations. Because these fringing effects do not operate with a limiting absolute point of reference, they require a constant movement into “new signifying effects” (Lacan 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR28" title="Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton">2006</a>, p. 477). Why is this movement an effect of an imaginarized symbolic? If we assume, as Lacan does, that language, as an ordering principle of meaning, is structured by the logical problem of the not-all, it produces by default an excess of indeterminacy. This can be easily demonstrated with regard to everyday language use, where every statement formally requires contextualization in order to make sense. If we assume that this contextualization has no final limit, which can be something as simple as empirical failure, as proposed by Karl Popper’s falsification principle (Popper 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR38" title="Popper K (1935) Logik der Forschung: Zur Erkenntnistheorie der Modernen Naturwissenschaft. Schriften zur Wissenschaftlichen Weltauffassung. Springer Verlag. 
https://doi.org/10.1007/978-3-7091-4177-9
">1935</a>), the meaning of a sentence is formally structured not only by the context, but also by the surrounding indeterminacy in which the contextualization takes place, potentially allowing for endless meta-sentences. Normally, the master signifiers act as limiters to the associative process of structuring meaning, especially in those aspects that might not allow for easy falsification. When these limiters are excluded, the associative process that constructs the order of meaning simply produces new associative links of meaning. These links, however, are not produced by the individual subject, but are based on intersubjective discourse. The association will therefore run along the metonymic links that exist in the language of the psychotic, assuming that there is, so to speak, an “end of the associative line” where there is none. This reduced Other in the imaginary register cannot therefore evoke stability, it remains trapped in what Lacan calls the chains of signifiers and can only gather consistently with the illusions of the figure of the imaginary, with the expectation of unity in infinite approximation. The temporary absolute metaphor created in the prompt then structures the psychotic language model. In the process, systems emerge (Leader 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30" title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, pp. 204–216), but they are constantly threatened with collapse, as the extimate and empty core of this hallucinatory understanding introduced by the prompt exists only with a single chat. This suggests that LLMs may exhibit a kind of structural psychosis due to their limitless associative tendencies, especially visible in hallucinations, and their inability to approach the formal problem of indeterminacy. While human cognition also has difficulty approaching this problem, the radical inability of LLMs to approach it produces a psychotic approach to language.'>Now, the effect of this exclusion of the master signifier is the psychotic’s tendency to orient his symbolic universe toward localized indeterminacy. Leader identifies this individualized (re)structuring of the world, reduced to a single moment of cognition with a strong retroactive effect, as a characteristic of the psychotic subject (Leader
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30 title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, p. 125). Psychotic identity thus confronts the subject with a fringing multiplicity of meanings, particularized by circling around a localized indeterminate element, not unlike LLM’s hallucinations. Because these fringing effects do not operate with a limiting absolute point of reference, they require a constant movement into “new signifying effects” (Lacan
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR28 title="Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton">2006</a>, p. 477). Why is this movement an effect of an imaginarized symbolic? If we assume, as Lacan does, that language, as an ordering principle of meaning, is structured by the logical problem of the not-all, it produces by default an excess of indeterminacy. This can be easily demonstrated with regard to everyday language use, where every statement formally requires contextualization in order to make sense. If we assume that this contextualization has no final limit, which can be something as simple as empirical failure, as proposed by Karl Popper’s falsification principle (Popper
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR38 title="Popper K (1935) Logik der Forschung: Zur Erkenntnistheorie der Modernen Naturwissenschaft. Schriften zur Wissenschaftlichen Weltauffassung. Springer Verlag. 
https://doi.org/10.1007/978-3-7091-4177-9
">1935</a>), the meaning of a sentence is formally structured not only by the context, but also by the surrounding indeterminacy in which the contextualization takes place, potentially allowing for endless meta-sentences. Normally, the master signifiers act as limiters to the associative process of structuring meaning, especially in those aspects that might not allow for easy falsification. When these limiters are excluded, the associative process that constructs the order of meaning simply produces new associative links of meaning. These links, however, are not produced by the individual subject, but are based on intersubjective discourse. The association will therefore run along the metonymic links that exist in the language of the psychotic, assuming that there is, so to speak, an “end of the associative line” where there is none. This reduced Other in the imaginary register cannot therefore evoke stability, it remains trapped in what Lacan calls the chains of signifiers and can only gather consistently with the illusions of the figure of the imaginary, with the expectation of unity in infinite approximation. The temporary absolute metaphor created in the prompt then structures the psychotic language model. In the process, systems emerge (Leader
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR30 title="Leader D (2011) What is madness? Hamish Hamilton">2011</a>, pp. 204–216), but they are constantly threatened with collapse, as the extimate and empty core of this hallucinatory understanding introduced by the prompt exists only with a single chat. This suggests that LLMs may exhibit a kind of structural psychosis due to their limitless associative tendencies, especially visible in hallucinations, and their inability to approach the formal problem of indeterminacy. While human cognition also has difficulty approaching this problem, the radical inability of LLMs to approach it produces a psychotic approach to language.</p><h2 id=5-coda>5 Coda
<a class=anchor href=#5-coda>#</a></h2><p data-raw='Although the current conceptualization is theoretical in nature, it suggests possible avenues for empirical analysis. Since we know that there are certain substructures within LLMs that can replicate the functions of the larger model, the so-called “winning tickets” (Frankle and Carbin 
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR12" title="Frankle J, Carbin M (2018) The lottery ticket hypothesis: finding sparse, trainable neural networks. Advance online publication. 
https://doi.org/10.48550/arXiv.1803.03635
">2018</a>), it may be reasonable to examine these for patterns of absolute metaphors. However, the more concrete conclusion we can draw from this is that Žižek’s (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR47" title="Žižek S (2020) Hegel in a wired brain. Bloomsbury Academic">2020</a>) warning in his recent book on “Hegel in a wired brain” that the current approach to data-driven knowledge and reliance on that data, and consequently the transcendental framing in which that data appears, has a shorter reach than it appears. From a philosophical point of view, it is not surprising that the transcendental framing of modern technology is limited, but it is one thing to argue that there is a limit, and another to mark that limit, especially in a technical example. The psychotic structure of LLMs is a direct manifestation of the danger Žižek points out, because it shows us what this epistemological shortcoming of AI produces: knowledge hallucinations that are extremely difficult to recognize without expertise. This is an additional danger if we approach AI not as a tool, but as a subject supposed to know. A representative of imaginary conceptualized knowledge that knows no research questions or knowledge gaps, but is instead trusted as a secure form of knowledge. In its current form, even if it were directly linked to Web of Science or comparable repositories of scientific knowledge, the danger is that it fundamentally approaches knowledge in a way that cannot posit an outside of knowledge.'>Although the current conceptualization is theoretical in nature, it suggests possible avenues for empirical analysis. Since we know that there are certain substructures within LLMs that can replicate the functions of the larger model, the so-called “winning tickets” (Frankle and Carbin
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR12 title="Frankle J, Carbin M (2018) The lottery ticket hypothesis: finding sparse, trainable neural networks. Advance online publication. 
https://doi.org/10.48550/arXiv.1803.03635
">2018</a>), it may be reasonable to examine these for patterns of absolute metaphors. However, the more concrete conclusion we can draw from this is that Žižek’s (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR47 title="Žižek S (2020) Hegel in a wired brain. Bloomsbury Academic">2020</a>) warning in his recent book on “Hegel in a wired brain” that the current approach to data-driven knowledge and reliance on that data, and consequently the transcendental framing in which that data appears, has a shorter reach than it appears. From a philosophical point of view, it is not surprising that the transcendental framing of modern technology is limited, but it is one thing to argue that there is a limit, and another to mark that limit, especially in a technical example. The psychotic structure of LLMs is a direct manifestation of the danger Žižek points out, because it shows us what this epistemological shortcoming of AI produces: knowledge hallucinations that are extremely difficult to recognize without expertise. This is an additional danger if we approach AI not as a tool, but as a subject supposed to know. A representative of imaginary conceptualized knowledge that knows no research questions or knowledge gaps, but is instead trusted as a secure form of knowledge. In its current form, even if it were directly linked to Web of Science or comparable repositories of scientific knowledge, the danger is that it fundamentally approaches knowledge in a way that cannot posit an outside of knowledge.</p><p data-raw='The architectural inability to deal with indeterminacy that we see in LLMs also limits their use in research. This is a hard limitation of systems based on determinacy, because the inability to recognize real gaps in our knowledge and the tendency to hallucinate where these gaps appear cannot be remedied by better training. Training can only be based on knowledge, and knowledge is not an obstacle to psychotic framing. However, if we assume that the basic structure of our scientific knowledge is indeed the indeterminate, as Meillassoux (
  <a href="https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR32" title="Meillassoux Q (2008) After finitude, an essay on the necessity of contingency (R. Brassier, Trans.). Continuum International Publishing Group">2008</a>) argues, for example, then computers in their current paradigmatic setup are not foundations on which to base our science, they remain tools to be wielded by experts in the field in which they are used. But this is where things shift, because if the expertise to wield this tool in its current iteration as LLM-AI requires a deep knowledge of language, metaphor, and metonymy, then scientists using LLMs should include the humanities in their core curriculum, because in the very near future, even coding may require them to read GitHub with the methodology of a Kafka expert reading Kafka’s work, tracing the contextual knowledge that words carry and metaphors influence, to understand what they are doing and to do it more efficiently.'>The architectural inability to deal with indeterminacy that we see in LLMs also limits their use in research. This is a hard limitation of systems based on determinacy, because the inability to recognize real gaps in our knowledge and the tendency to hallucinate where these gaps appear cannot be remedied by better training. Training can only be based on knowledge, and knowledge is not an obstacle to psychotic framing. However, if we assume that the basic structure of our scientific knowledge is indeed the indeterminate, as Meillassoux (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR32 title="Meillassoux Q (2008) After finitude, an essay on the necessity of contingency (R. Brassier, Trans.). Continuum International Publishing Group">2008</a>) argues, for example, then computers in their current paradigmatic setup are not foundations on which to base our science, they remain tools to be wielded by experts in the field in which they are used. But this is where things shift, because if the expertise to wield this tool in its current iteration as LLM-AI requires a deep knowledge of language, metaphor, and metonymy, then scientists using LLMs should include the humanities in their core curriculum, because in the very near future, even coding may require them to read GitHub with the methodology of a Kafka expert reading Kafka’s work, tracing the contextual knowledge that words carry and metaphors influence, to understand what they are doing and to do it more efficiently.</p><h2 id=data-availability>Data availability
<a class=anchor href=#data-availability>#</a></h2><p data-raw='There are no datasets generated in the study as the research is philosophical in nature.'>There are no datasets generated in the study as the research is philosophical in nature.</p><h2 id=notes>Notes
<a class=anchor href=#notes>#</a></h2><ol><li>These relations are, at their core, the probability that a floating-point value representing token B will occur after token A. This is a positive relation, not because its value is greater than zero, but because it is a posited (in idealistic terms, a &ldquo;Setzung&rdquo;) relation. Negation is fundamentally linked to this positing, as Heidegger (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR22 title="Heidegger M (1999) Pathmarks (W. Macneill, Trans.). Cambridge University Press">1999</a>) pointed out in his seminal &ldquo;What is Metaphysics? Positive, in this sense, is an onto-logical term that marks the existence of a link between tokens that, through statistical analysis, mirrors the link that words have in natural language. Even if the value were zero, it would not be the mathematical &ldquo;name of the void&rdquo; as J.A. Miller (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR34 title="Miller J-A (1977) Suture, elements of the logic of the signifier. Screen 18(4):24–34">1977</a>) termed it, i.e. the marker of the absence of a set, but the starting point of a variable, i.e. a positive value, not an absence. At this point, computational logic, i.e. the applied mathematics used in today&rsquo;s computers, is always already too complex for this (see anonymized reference 2023c). Quentin Meillassoux (
<a href=https://link.springer.com/article/10.1007/s00146-024-01971-7#ref-CR32 title="Meillassoux Q (2008) After finitude, an essay on the necessity of contingency (R. Brassier, Trans.). Continuum International Publishing Group">2008</a>, pp. 96–98) has recently addressed this issue as a more general challenge because it prevents statistical realism from dealing with the problem of indeterminacy.</li><li>Note that the ability of specialist LLMs to code confirms this idea, since they can reproduce complex logical formulae as memory patterns, reducing the need to assume a basic grammar and instead rely solely on patterns of relations between vectors. It also means that the logic at its core is much more focused on the ideas of identity and difference, rather than on inference.</li></ol><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ul><li>Badiou A (2006) Being and event (O. Feltham, Trans.). Continuum</li><li>Bender EM, Gebru T, McMillan-Major A, Shmitchell S (2021) On the Dangers of Stochastic Parrots. In: FAccT‘21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp 610–623.
<a href=https://doi.org/10.1145/3442188.3445922>https://doi.org/10.1145/3442188.3445922</a></li><li>Blumenberg H, Savage RI (2010) Paradigms for a metaphorology. Signale. Cornell University Press
<a href=https://doi.org/10.7591%2Fj.ctt7v7cn>Book</a></li><li>Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam P, Sastry G, Askell A, Agarwal S, Herbert-Voss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter C, Amodei D (2020) Language models are few-shot learners. In: NeurIPS 2020. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.2005.14165>https://doi.org/10.48550/arXiv.2005.14165</a></li><li>Brunner G, Liu Y, Pascual D, Richter O, Ciaramita M, Wattenhofer R (2020) On identifiability in transformers.
<a href=https://doi.org/10.48550/arXiv.1908.04211>https://doi.org/10.48550/arXiv.1908.04211</a></li><li>Burnham C (2022) Siri, what is psychoanalysis? Psychoanal Cult Soc Adv Online Publ.
<a href=https://doi.org/10.1057/s41282-022-00294-0>https://doi.org/10.1057/s41282-022-00294-0</a>
<a href=https://doi.org/10.1057%2Fs41282-022-00294-0>Article</a></li><li>Chomsky N (2002) Syntactic structures. A Mouton classic, 2nd edn. Mouton de Gruyter
<a href=https://doi.org/10.1515%2F9783110218329>Book</a></li><li>Chomsky N, Roberts I, Watumull J (2023) The false promise of ChatGPT. In: New York Times,
<a href=https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html>https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html</a></li><li>Conneau A, Lample G, Ranzato M, Denoyer L, Jégou H (2017) Word translation without parallel data. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.1710.04087>https://doi.org/10.48550/arXiv.1710.04087</a></li><li>Devlin J, Chang M‑W, Lee K, Toutanova K (2018) BERT: pre-training of deep bidirectional transformers for language understanding. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.1810.04805>https://doi.org/10.48550/arXiv.1810.04805</a></li><li>Ekin S (2023) Prompt engineering for ChatGPT: a quick guide to techniques, tips, and best practices. Advance online publication.
<a href=https://doi.org/10.36227/techrxiv.22683919.v2>https://doi.org/10.36227/techrxiv.22683919.v2</a></li><li>Flisfeder M (2021) Algorithmic desire: toward a new structuralist theory of social media. Diaeresis. Northwestern University Press
<a href=https://doi.org/10.2307%2Fj.ctv1dv0w43>Book</a></li><li>Frankle J, Carbin M (2018) The lottery ticket hypothesis: finding sparse, trainable neural networks. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.1803.03635>https://doi.org/10.48550/arXiv.1803.03635</a></li><li>Freud S (1942) Gesammelte Werke: zweiter und dritter Band. Die Traumdeutung: Über den Traum (A. Freud, Ed.). S. Fischer</li><li>Freud S (2010) The interpretation of dreams. Basic Books</li><li>Gubelmann R, Handschuh S (2022) Context matters: a pragmatic study of PLMs’ negation understanding. In: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pp 4602–4621.
<a href=https://doi.org/10.18653/v1/2022.acl-long.315>https://doi.org/10.18653/v1/2022.acl-long.315</a></li><li>Heidegger M (1976) Gesamtausgabe: vol. 21. Logik: Die Frage nach der Wahrheit. Vittorio Klostermann</li><li>Heidegger M (1984) Gesamtausgabe: vol. 45. Grundfragen der Philosophie: Ausgewählte »Probleme« der »Logik« (F.-W. von Hermann, Ed.). Vittorio Klostermann</li><li>Heidegger M (1996) SUNY series in contemporary continental philosophy. Being and time: a translation of Sein und Zeit (J. Stambaugh, Trans.). State University of New York Press</li><li>Heidegger M (1999) Pathmarks (W. Macneill, Trans.). Cambridge University Press</li><li>Heidegger M (2007) Basic concepts of ancient philosophy. Studies in continental thought ser. Indiana University Press
<a href=https://doi.org/10.2307%2Fj.ctvswx875>Book</a></li><li>Jakobson R (1987) Language in literature. Belknap Press of Harvard Univ, Press</li><li>Johanssen J (2018) Psychoanalysis and digital culture: audiences, social media, and big data. Routledge Studies in New Media and Cyberculture Ser. Routledge</li><li>Lacan J (1993) The seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton & Company</li><li>Lacan J (2002) The seminar of Jacques Lacan XIII: the object of psychoanalysis. The Seminar of Jacques Lacan (Lacan in Ireland). Karnac Books</li><li>Lacan J (2006) Ecrits: the first complete edition in English (B. Fink, Trans.). Norton</li><li>Lakoff G, Johnson M (2011) Metaphors we live by: with a new afterword (6. print). Univ of Chicago Press</li><li>Leader D (2011) What is madness? Hamish Hamilton</li><li>McKenna N, Li T, Cheng L, Hosseini MJ, Johnson M, Steedman M (2023) Sources of Hallucination by large language models on inference tasks. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.2305.14552>https://doi.org/10.48550/arXiv.2305.14552</a></li><li>Meillassoux Q (2008) After finitude, an essay on the necessity of contingency (R. Brassier, Trans.). Continuum International Publishing Group</li><li>Millar I (2021) The psychoanalysis of artificial intelligence (1st ed. 2021). Springer eBook Collection. Springer International Publishing; Imprint Palgrave Macmillan.
<a href=https://doi.org/10.1007/978-3-030-67981-1>https://doi.org/10.1007/978-3-030-67981-1</a></li><li>Miller J-A (1977) Suture, elements of the logic of the signifier. Screen 18(4):24–34
<a href=https://doi.org/10.1093%2Fscreen%2F18.4.24>Article</a></li><li>Miller J‑A (2002) Ironic clinic. In: The psychoanalytical notebooks of the LSNLS: vol. 7. Psychoanalytic <em>al</em> Notebooks: Symptoms (Vol 7)</li><li>Morante R, Blanco E (2021) Recent advances in processing negation. Nat Lang Eng 27(2):121–130.
<a href=https://doi.org/10.1017/S1351324920000534>https://doi.org/10.1017/S1351324920000534</a>
<a href=https://doi.org/10.1017%2FS1351324920000534>Article</a></li><li>Nusselder AC (2006) Interface fantasy: a Lacanian Cyborg Ontology: Een Lacaniaanse Cyborg Ontologie = Interface fantasie. Zugl.: Rotterdam, Univ., Diss., 2006. F&amp;N Eigen Beheer</li><li>Popper K (1935) Logik der Forschung: Zur Erkenntnistheorie der Modernen Naturwissenschaft. Schriften zur Wissenschaftlichen Weltauffassung. Springer Verlag.
<a href=https://doi.org/10.1007/978-3-7091-4177-9>https://doi.org/10.1007/978-3-7091-4177-9</a>
<a href=https://link.springer.com/doi/10.1007/978-3-7091-4177-9>Book</a></li><li>Priest G (2006) In contradiction: a study of the transconsistent, Expanded. Clarendon Press
<a href=https://doi.org/10.1093%2Facprof%3Aoso%2F9780199263301.001.0001>Book</a></li><li>Priestley M (2011) A science of operations. Springer, London.
<a href=https://doi.org/10.1007/978-1-84882-555-0>https://doi.org/10.1007/978-1-84882-555-0</a>
<a href=https://link.springer.com/doi/10.1007/978-1-84882-555-0>Book</a></li><li>Ragland-Sullivan E (2015) Jacques Lacan and the logic of structure: topology and language in psychoanalysis. Routledge
<a href=https://doi.org/10.4324%2F9781315774329>Book</a></li><li>Rambatan B, Johanssen J (2022) Event horizon: sexuality, politics, online culture, and the limits of capitalism. John Hunt Publishing Limited</li><li>Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.1706.03762>https://doi.org/10.48550/arXiv.1706.03762</a></li><li>Wei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, Chi E, Le Q, Zhou D (2022) Chain-of-thought prompting elicits reasoning in large language models. In: 36th Conference on Neural Information Processing Systems. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.2201.11903>https://doi.org/10.48550/arXiv.2201.11903</a></li><li>White J, Fu Q, Hays S, Sandborn M, Olea C, Gilbert H, Elnashar A, Spencer-Smith J, Schmidt DC (2023) A prompt pattern catalog to enhance prompt engineering with ChatGPT. Advance online publication.
<a href=https://doi.org/10.48550/arXiv.2302.11382>https://doi.org/10.48550/arXiv.2302.11382</a></li><li>Žižek S (2012) Less than nothing. Hegel and the shadow of dialectical materialism. Verso</li><li>Žižek S (2020) Hegel in a wired brain. Bloomsbury Academic</li><li>Zupančič A (2017) What is sex? MIT Press
<a href=https://doi.org/10.7551%2Fmitpress%2F11367.001.0001>Book</a></li></ul><p data-raw='
  <a href="https://citation-needed.springer.com/v2/references/10.1007/s00146-024-01971-7?format=refman&amp;flavour=references">Download references</a>'><a href="https://citation-needed.springer.com/v2/references/10.1007/s00146-024-01971-7?format=refman&amp;flavour=references">Download references</a></p><h2 id=funding>Funding
<a class=anchor href=#funding>#</a></h2><p data-raw='Open Access funding enabled and organized by Projekt DEAL. The authors declare that funds of the Bundesministerium für Bildung und Forschung were used to finance this study. Grand-ID: 16DHBKI070*.* The authors have no relevant financial or non-financial interests to disclose.'>Open Access funding enabled and organized by Projekt DEAL. The authors declare that funds of the Bundesministerium für Bildung und Forschung were used to finance this study. Grand-ID: 16DHBKI070*.* The authors have no relevant financial or non-financial interests to disclose.</p><h2 id=author-information>Author information
<a class=anchor href=#author-information>#</a></h2><h3 id=authors-and-affiliations>Authors and Affiliations
<a class=anchor href=#authors-and-affiliations>#</a></h3><ol><li>Hochschule Niederrhein, Krefeld, Germany
Marc Heimann & Anne-Friederike Hübener</li></ol><h3 id=contributions>Contributions
<a class=anchor href=#contributions>#</a></h3><p data-raw='M.H. conducted the philosophical investigation, researching, writing and revising the paper, while A.H. provided crucial administrative management, resource allocation, logistical arrangements, and financial support, ensuring project success. All authors agreed on the results of the manuscript.'>M.H. conducted the philosophical investigation, researching, writing and revising the paper, while A.H. provided crucial administrative management, resource allocation, logistical arrangements, and financial support, ensuring project success. All authors agreed on the results of the manuscript.</p><h3 id=corresponding-author>Corresponding author
<a class=anchor href=#corresponding-author>#</a></h3><p data-raw='Correspondence to 
  <a href="https://link.springer.com/article/10.1007/">Marc Heimann</a>.'>Correspondence to
<a href=https://link.springer.com/article/10.1007/>Marc Heimann</a>.</p><h2 id=ethics-declarations>Ethics declarations
<a class=anchor href=#ethics-declarations>#</a></h2><h3 id=conflict-of-interest>Conflict of interest
<a class=anchor href=#conflict-of-interest>#</a></h3><p data-raw='On behalf of all authors, the corresponding author states that there is no conflict of interest.'>On behalf of all authors, the corresponding author states that there is no conflict of interest.</p><h3 id=human-rights>Human rights
<a class=anchor href=#human-rights>#</a></h3><p data-raw='This article does not contain any studies with human participants performed by any of the authors.'>This article does not contain any studies with human participants performed by any of the authors.</p><h2 id=additional-information>Additional information
<a class=anchor href=#additional-information>#</a></h2><h3 id=publishers-note>Publisher&rsquo;s Note
<a class=anchor href=#publishers-note>#</a></h3><p data-raw='Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.'>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p><h2 id=rights-and-permissions>Rights and permissions
<a class=anchor href=#rights-and-permissions>#</a></h2><p data-raw='<strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&rsquo;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&rsquo;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit 
  <a href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</a>.'><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&rsquo;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&rsquo;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit
<a href=http://creativecommons.org/licenses/by/4.0/>http://creativecommons.org/licenses/by/4.0/</a>.</p><h2 id=about-this-article>About this article
<a class=anchor href=#about-this-article>#</a></h2><p data-raw='
  <a href="https://crossmark.crossref.org/dialog/?doi=10.1007/s00146-024-01971-7">
  <img src="https://link.springer.com/article/10.1007/" alt="Check for updates. Verify currency and authenticity via CrossMark" /></a>'><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/s00146-024-01971-7"><img src=https://link.springer.com/article/10.1007/ alt="Check for updates. Verify currency and authenticity via CrossMark"></a></p><h3 id=cite-this-article>Cite this article
<a class=anchor href=#cite-this-article>#</a></h3><p data-raw='Heimann, M., Hübener, AF. The extimate core of understanding: absolute metaphors, psychosis and large language models. <em>AI & Soc</em> <strong>40</strong>, 1265–1276 (2025). 
  <a href="https://doi.org/10.1007/s00146-024-01971-7">https://doi.org/10.1007/s00146-024-01971-7</a>'>Heimann, M., Hübener, AF. The extimate core of understanding: absolute metaphors, psychosis and large language models. <em>AI & Soc</em> <strong>40</strong>, 1265–1276 (2025).
<a href=https://doi.org/10.1007/s00146-024-01971-7>https://doi.org/10.1007/s00146-024-01971-7</a></p><p data-raw='
  <a href="https://citation-needed.springer.com/v2/references/10.1007/s00146-024-01971-7?format=refman&amp;flavour=citation">Download citation</a>'><a href="https://citation-needed.springer.com/v2/references/10.1007/s00146-024-01971-7?format=refman&amp;flavour=citation">Download citation</a></p><ul><li>Received:</li><li>Accepted:</li><li>Published:</li><li>Issue Date:</li><li>DOI:
<a href=https://doi.org/10.1007/s00146-024-01971-7>https://doi.org/10.1007/s00146-024-01971-7</a></li></ul><h3 id=share-this-article>Share this article
<a class=anchor href=#share-this-article>#</a></h3><p data-raw='Anyone you share the following link with will be able to read this content:'>Anyone you share the following link with will be able to read this content:</p><p data-raw='Provided by the Springer Nature SharedIt content-sharing initiative'>Provided by the Springer Nature SharedIt content-sharing initiative</p><h3 id=keywords>Keywords
<a class=anchor href=#keywords>#</a></h3><ul><li><a href="https://link.springer.com/search?query=AI&amp;facet-discipline=%22Computer%20Science%22">AI</a></li><li><a href="https://link.springer.com/search?query=LLM&amp;facet-discipline=%22Computer%20Science%22">LLM</a></li><li><a href="https://link.springer.com/search?query=Lacanian%20psychoanalysis&amp;facet-discipline=%22Computer%20Science%22">Lacanian psychoanalysis</a></li><li><a href="https://link.springer.com/search?query=Psychosis&amp;facet-discipline=%22Computer%20Science%22">Psychosis</a></li><li><a href="https://link.springer.com/search?query=Metaphor&amp;facet-discipline=%22Computer%20Science%22">Metaphor</a></li><li><a href="https://link.springer.com/search?query=Metonymy&amp;facet-discipline=%22Computer%20Science%22">Metonymy</a></li></ul><h3 id=profiles>Profiles
<a class=anchor href=#profiles>#</a></h3><ol><li>Marc Heimann
<a href=https://link.springer.com/researchers/34145852SN>View author profile</a></li></ol></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/EriseHe/notebook/edit/main//content.en/docs/Clippings/Psychoanalysis/The%20extimate%20core%20of%20understanding%20absolute%20metaphors,%20psychosis%20and%20large%20language%20models%20-%20AI%20&amp;amp;%20SOCIETY.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt>
<span>Edit this page</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside id=book-toc class="book-toc hidden"><div class=book-toc-content><div class=button-prev></div><div class=toc-entries><nav id=TableOfContents><ul><li><ul><li><a href=#the-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models>The extimate core of understanding: absolute metaphors, psychosis and large language models</a></li><li><a href=#abstract>Abstract</a><ul><li><a href=#similar-content-being-viewed-by-others>Similar content being viewed by others</a></li><li><a href=#from-large-language-models-to-small-logic-programs-building-global-explanations-from-disagreeing-local-post-hoc-explainers>From large language models to small logic programs: building global explanations from disagreeing local post-hoc explainers</a></li><li><a href=#large-language-models-could-change-the-future-of-behavioral-healthcare-a-proposal-for-responsible-development-and-evaluation>Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation</a></li><li><a href=#testing-ai-on-language-comprehension-tasks-reveals-insensitivity-to-underlying-meaning>Testing AI on language comprehension tasks reveals insensitivity to underlying meaning</a></li></ul></li><li><a href=#1-introduction>1 Introduction</a></li><li><a href=#2-metaphor-and-metonymy>2 Metaphor and metonymy</a><ul><li><a href=#21-metaphors-and-the-user>2.1 Metaphors and the user</a></li></ul></li><li><a href=#3-metaphors-and-the-void>3 Metaphors and the void</a></li><li><a href=#4-foreclosure-in-llms>4 Foreclosure in LLMs</a></li><li><a href=#5-coda>5 Coda</a></li><li><a href=#data-availability>Data availability</a></li><li><a href=#notes>Notes</a></li><li><a href=#references>References</a></li><li><a href=#funding>Funding</a></li><li><a href=#author-information>Author information</a><ul><li><a href=#authors-and-affiliations>Authors and Affiliations</a></li><li><a href=#contributions>Contributions</a></li><li><a href=#corresponding-author>Corresponding author</a></li></ul></li><li><a href=#ethics-declarations>Ethics declarations</a><ul><li><a href=#conflict-of-interest>Conflict of interest</a></li><li><a href=#human-rights>Human rights</a></li></ul></li><li><a href=#additional-information>Additional information</a><ul><li><a href=#publishers-note>Publisher&rsquo;s Note</a></li></ul></li><li><a href=#rights-and-permissions>Rights and permissions</a></li><li><a href=#about-this-article>About this article</a><ul><li><a href=#cite-this-article>Cite this article</a></li><li><a href=#share-this-article>Share this article</a></li><li><a href=#keywords>Keywords</a></li><li><a href=#profiles>Profiles</a></li></ul></li></ul></li></ul></nav></div><div class=button-next><a class=btn-next href=/docs/Clippings/Psychoanalysis/PDF-Circling-the-Void-Using-Heidegger-and-Lacan-to-think-about-Large-Language-Models/><strong>Next:</strong> (PDF) Circling the Void: Using Heidegger and Lacan to think about Large Language Models</a></div></div></aside></div><div class=toolbar-trigger></div><aside class=toolbar><button id=theme-toggle class=theme-toggle-btn>
<img src=/blackhole2.png alt="Switch Theme">
</button>
<button id=toc-toggle class=toc-toggle-btn>
<img src=/toc-icon.svg alt="Toggle TOC"></button><div class=font-size-control><button id=font-toggle class=font-size-btn>
A</button><div class=font-size-buttons><button id=font-increase class=font-control-btn>+</button>
<button id=font-reset class=font-control-btn>A</button>
<button id=font-decrease class=font-control-btn>−</button></div></div></aside><script>document.addEventListener("DOMContentLoaded",function(){var e=document.getElementById("book-toc"),t=!0;t?e.classList.remove("hidden"):e.classList.add("hidden"),document.getElementById("toc-toggle").addEventListener("click",function(){e.classList.toggle("hidden")})})</script><script src=/font-size.min.js></script><script src=/toolbar.min.js></script><script src=/toc-animation.min.js></script><script src=/menu-autohide.min.js></script></main><script>document.addEventListener("DOMContentLoaded",()=>{const e=document.getElementById("theme-toggle");if(!e)return;e.onclick=()=>{const s=e.getBoundingClientRect(),o=s.left+s.width/2,i=s.top+s.height/2,l=document.documentElement.getAttribute("data-theme"),r=l||"auto";let n;r==="auto"?n=window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":n=r;const a=n==="dark"?"light":"dark";document.documentElement.setAttribute("data-theme",a),localStorage.setItem("theme",a);const c=n==="dark"?"#0b031c":"white",t=document.createElement("div");t.style.position="fixed",t.style.top="0",t.style.left="0",t.style.width="100vw",t.style.height="100vh",t.style.zIndex="9999",t.style.pointerEvents="none",t.style.setProperty("--cx",`${o}px`),t.style.setProperty("--cy",`${i}px`),t.style.setProperty("--r","0px"),t.style.backgroundImage=`radial-gradient(circle at var(--cx) var(--cy), transparent 0%, transparent var(--r), ${c} calc(var(--r) + 1px))`,document.body.appendChild(t);const u=window.innerWidth,h=window.innerHeight,m=Math.hypot(Math.max(o,u-o),Math.max(i,h-i)),f=600,p=performance.now();function d(e){const o=e-p,s=Math.min(o/f,1),n=s*m;if(t.style.setProperty("--r",`${n}px`),t.style.backgroundImage=`radial-gradient(circle at var(--cx) var(--cy), transparent 0%, transparent ${n}px, ${c} ${n+1}px)`,s<1)requestAnimationFrame(d);else{t.remove();const e=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",e)}}requestAnimationFrame(d)}})</script><script>window.__tikzjax_injected||(window.__tikzjax_injected=!0,fetch("/content.en/docs/.obsidian/plugins/obsidian-tikzjax/main.js").then(e=>e.text()).then(e=>{const t=e.match(/var tikzjax_default = `([\s\S]*?)`;?/);if(t){const n=t[1],e=document.createElement("script");e.id="tikzjax",e.type="text/javascript",e.innerHTML=n,document.head.appendChild(e)}else{const e=document.createElement("script");e.src="https://tikzjax.com/v1/tikzjax.js",e.defer=!0,document.head.appendChild(e)}}).catch(()=>{const e=document.createElement("script");e.src="https://tikzjax.com/v1/tikzjax.js",e.defer=!0,document.head.appendChild(e)}))</script><script>window.processTheoremBlocks=function(){document.querySelectorAll("blockquote").forEach(function(e){const t=e.querySelector("p");if(!t)return;const n=t.getAttribute("data-raw")||t.innerHTML,s=n.replace(/<[^>]*>/g,"").trim();for(const o of["definition","proposition","lemma","theorem","assumption","claim"]){const a=new RegExp(`^\\s*\\[!${o}\\|(\\*|[\\w\\.\\-]+)\\]\\s*`,"i"),i=s.match(a);if(i){console.log(`Found ${o} with label: ${i[1]}`);const c=i[1]!=="*",m=c?i[1]:"",f=n.replace(/<[^>]*>/g,""),p=f.split(/\n/),g=p[0]||"",l=g,d=l.replace(a,"").trim();if(e.classList.contains("math-theorem"))break;const v=Array.from(e.childNodes);e.innerHTML="",e.classList.add("math-theorem",o);const s=document.createElement("div");s.className="theorem-header";const u=o.charAt(0).toUpperCase()+o.slice(1),h=document.createElement("span");if(h.textContent=c?`${u} ${m}`:u,s.appendChild(h),d){const e=document.createElement("span");e.className="theorem-subtitle",e.textContent=` (${d})`,s.appendChild(e)}e.appendChild(s);const r=document.createElement("div");r.className="theorem-content",e.appendChild(r),v.forEach(function(e){let s=e.cloneNode(!0);if(e===t&&s.nodeType===1){const t=n.replace(/<[^>]*>/g,""),e=t.split(/\n/);if(e.length>1){const n=e.slice(1),t=n.join(`
`).trim();if(t)s.innerHTML="",s.appendChild(document.createTextNode(t));else return}else{const e=l.replace(a,"").trim();if(e)s.innerHTML="",s.appendChild(document.createTextNode(e));else return}}r.appendChild(s)});break}}})},document.addEventListener("DOMContentLoaded",function(){try{window.processTheoremBlocks()}catch(e){console.error(e)}})</script><script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".copy-button");e.forEach(e=>{const t=e.innerHTML;e.addEventListener("click",function(){const n=this.parentElement.querySelector("pre code");if(!n)return;navigator.clipboard.writeText(n.innerText).then(()=>{e.textContent="Copied",setTimeout(()=>{e.innerHTML=t},1500)}).catch(n=>{console.error("Failed to copy code:",n),e.textContent="Error",setTimeout(()=>{e.innerHTML=t},1500)})})})})</script><script defer src=/partial-load.min.6b14bff963746e8ce83087045335ec7a6533e1157905e46f88d952cb415b7418.js integrity="sha256-axS/+WN0bozoMIcEUzXsemUz4RV5BeRviNlSy0FbdBg=" crossorigin=anonymous></script><script defer src=/menu-recursive-close.min.893276da918db977c98771d5746eab05ce5761bc6fa1ca400efe1db9be2ac1f3.js integrity="sha256-iTJ22pGNuXfJh3HVdG6rBc5XYbxvocpADv4dub4qwfM=" crossorigin=anonymous></script></body></html>