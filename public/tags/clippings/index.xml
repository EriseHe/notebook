<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Clippings on 学习笔记</title><link>http://localhost:1314/tags/clippings/</link><description>Recent content in Clippings on 学习笔记</description><generator>Hugo</generator><language>en</language><lastBuildDate>Fri, 17 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1314/tags/clippings/index.xml" rel="self" type="application/rss+xml"/><item><title>The extimate core of understanding: absolute metaphors, psychosis and large language models - AI &amp; SOCIETY</title><link>http://localhost:1314/docs/Clippings/Psychoanalysis/The-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models-AI-SOCIETY/</link><pubDate>Fri, 17 May 2024 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Psychoanalysis/The-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models-AI-SOCIETY/</guid><description>&lt;p>Advertisement&lt;/p>
&lt;h2 id="the-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models">
 The extimate core of understanding: absolute metaphors, psychosis and large language models
 &lt;a class="anchor" href="#the-extimate-core-of-understanding-absolute-metaphors-psychosis-and-large-language-models">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>Main Paper&lt;/li>
&lt;li>
 &lt;a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research">Open access&lt;/a>&lt;/li>
&lt;li>Published:&lt;/li>
&lt;li>Volume 40, pages 1265–1276, (2025)&lt;/li>
&lt;li>
 &lt;a href="https://link.springer.com/article/10.1007/?utm_source=chatgpt.com#citeas">Cite this article&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>You have full access to this 
 &lt;a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research">open access&lt;/a> article&lt;/p>
&lt;p>
 &lt;a href="https://link.springer.com/journal/146">
 &lt;img src="https://media.springernature.com/w72/springer-static/cover-hires/journal/146?as=webp" alt="" /> AI &amp;amp; SOCIETY&lt;/a> 
 &lt;a href="https://link.springer.com/journal/146/aims-and-scope">Aims and scope&lt;/a> 
 &lt;a href="https://submission.springernature.com/new-submission/146/3">Submit manuscript&lt;/a>&lt;/p>
&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;p>This paper delves into the striking parallels between the linguistic patterns of Large Language Models (LLMs) and the concepts of psychosis in Lacanian psychoanalysis. Lacanian theory, with its focus on the formal and logical underpinnings of psychosis, provides a compelling lens to juxtapose human cognition and AI mechanisms. LLMs, such as GPT-4, appear to replicate the intricate metaphorical and metonymical frameworks inherent in human language. Although grounded in mathematical logic and probabilistic analysis, the outputs of LLMs echo the nuanced linguistic associations found in metaphor and metonymy, suggesting a mirroring of human linguistic structures. A pivotal point in this discourse is the exploration of “absolute metaphors”—core gaps in reasoning discernible in both AI models and human thought processes and central to the Lacanian conceptualization of psychosis. Despite the traditional divide between AI research and continental philosophy, this analysis embarks on an innovative journey, utilizing Lacanian philosophy to unravel the logic of AI, using concepts established in the continental discourse on logic, rather than the analytical tradition.&lt;/p></description></item><item><title>(PDF) Circling the Void: Using Heidegger and Lacan to think about Large Language Models</title><link>http://localhost:1314/docs/Clippings/Psychoanalysis/PDF-Circling-the-Void-Using-Heidegger-and-Lacan-to-think-about-Large-Language-Models/</link><pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Psychoanalysis/PDF-Circling-the-Void-Using-Heidegger-and-Lacan-to-think-about-Large-Language-Models/</guid><description>&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;p>The paper aims to unite two currently distinct ways of thinking about and working with language. Large language models and continental philosophy, especially Martin Heidegger&amp;rsquo;s thinking about language and, building on Sigmund Freud, Jacques Lacan&amp;rsquo;s structural psychoanalysis. We show that the concept of language that Heidegger, Freud, and Lacan discussed and utilized in clinical frameworks is quite well matched by modern LLMs. This allows us to discuss a problem of negation and negativity that is central to continental discourse but absent from current LLM research. This also means that we offer a radically different approach than is usual in the philosophy of artificial intelligence, since we base our concepts on thinkers who are often neglected in the discourse of analytic philosophy that is closer to AI research. To this end, we also indicate where the ontological differences of the proposed approach lie. Our aim, however, is to address both AI researchers and continental philosophers.&lt;/p></description></item><item><title>Algorithmic unconscious: why psychoanalysis helps in understanding AI - Humanities and Social Sciences Communications</title><link>http://localhost:1314/docs/Clippings/Psychoanalysis/Algorithmic-unconscious-why-psychoanalysis-helps-in-understanding-AI-Humanities-and-Social-Sciences-Communications/</link><pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Psychoanalysis/Algorithmic-unconscious-why-psychoanalysis-helps-in-understanding-AI-Humanities-and-Social-Sciences-Communications/</guid><description>&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;p>The central hypothesis of this paper is that the concepts and methods of psychoanalysis can be applied to the study of AI and human/AI interaction. The paper connects three research fields: machine behavior approach, psychoanalysis and anthropology of science. In the “Machine behavior: research perspectives” section, I argue that the behavior of AI systems cannot be studied only in a logical-mathematical or engineering perspective. We need to study AI systems not merely as engineering artifacts, but as a class of social actors with particular behavioral patterns and ecology. Hence, AI behavior cannot be fully understood without human and social sciences. In the “Why an unconscious for AI? What this paper is about” section, I give some clarifications about the aims of the paper. In the “Unconscious and technology. Lacan and Latour” section, I introduce the central thesis. I propose a re-interpretation of Lacan’s psychoanalysis through Latour’s anthropology of sciences. The aim of this re-interpretation is to show that the concept of unconscious is not so far from technique and technology. In the “The difficulty of being an AI” section, I argue that AI is a new stage in the human identification process, namely, a new development of the unconscious identification. After the imaginary and symbolic registers, AI is the third register of identification. Therefore, AI extends the movement that is at work in the Lacanian interpretation of the mirror stage and Oedipus complex and which Latour’s reading helps us to clarify. From this point of view, I describe an AI system as a set of three contrasting forces: the human desire for identification, logic and machinery. In the “Miscomputation and information” section, I show how this interpretative model improves our understanding of AI.&lt;/p></description></item><item><title>Artificial intelligence and psychoanalysis: is it time for psychoanalyst.AI? - PMC</title><link>http://localhost:1314/docs/Clippings/Psychoanalysis/Artificial-intelligence-and-psychoanalysis-is-it-time-for-psychoanalyst.AI-PMC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Psychoanalysis/Artificial-intelligence-and-psychoanalysis-is-it-time-for-psychoanalyst.AI-PMC/</guid><description>&lt;p>
 &lt;img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-frontpsychiat.gif" alt="Frontiers in Psychiatry logo" />&lt;/p>
&lt;p>. 2025 Apr 7;16:1558513. doi: 
 &lt;a href="https://doi.org/10.3389/fpsyt.2025.1558513">10.3389/fpsyt.2025.1558513&lt;/a>&lt;/p>
&lt;h2 id="artificial-intelligence-and-psychoanalysis-is-it-time-for-psychoanalystai">
 Artificial intelligence and psychoanalysis: is it time for psychoanalyst.AI?
 &lt;a class="anchor" href="#artificial-intelligence-and-psychoanalysis-is-it-time-for-psychoanalystai">#&lt;/a>
&lt;/h2>
&lt;p>
 &lt;a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rabeyron%20T%22%5BAuthor%5D">Thomas Rabeyron&lt;/a> &lt;sup>1,&lt;/sup>&lt;sup>*&lt;/sup>&lt;/p>
&lt;p>PMCID: PMC12009934 PMID: 
 &lt;a href="https://pubmed.ncbi.nlm.nih.gov/40259971/">40259971&lt;/a>&lt;/p>
&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;p>The current development of artificial intelligences (AI) is leading to major transformations within society. In this context, we observe how some of these AIs are spontaneously used by individuals as confidants, and even as romantic partners. The emergence of such relationships with AIs raises questions about their integration in psychiatry and the possibility of developing “digital therapists”. In this regard, we highlight four key elements (accessibility and availability; confidentiality; knowledge; memory) to compare what an AI offers in comparison to a human therapist. We also discuss the results of the studies that have already investigated the use of such AIs in psychotherapy, particularly in the fields of depression and anxiety. We then propose to reflect more specifically on the possibility of creating a “psychoanalyst.AI,” which leads us to examine the elements of the therapeutic relationship (transference, free association, play, dreams, reflexivity, and narrativity) with an AI. In conclusion, we offer some reflections on the relevance of considering AIs as “therapeutic artifact,” while taking into account the ethical issues raised by the use of AIs in therapeutic settings.&lt;/p></description></item><item><title>Attention Is All You Need</title><link>http://localhost:1314/docs/Clippings/LLM/Attention-Is-All-You-Need/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/LLM/Attention-Is-All-You-Need/</guid><description>&lt;p>[Submitted on 12 Jun 2017 (
 &lt;a href="https://arxiv.org/abs/1706.03762v1">v1&lt;/a>), last revised 2 Aug 2023 (this version, v7)]&lt;/p>
&lt;h2 id="titleattention-is-all-you-need">
 Title:Attention Is All You Need
 &lt;a class="anchor" href="#titleattention-is-all-you-need">#&lt;/a>
&lt;/h2>
&lt;p>
 &lt;a href="https://arxiv.org/pdf/1706.03762">View PDF&lt;/a> 
 &lt;a href="https://arxiv.org/html/1706.03762v7">HTML (experimental)&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Abstract: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.&lt;/p></description></item><item><title>FinTextSim: Enhancing Financial Text Analysis with BERTopic</title><link>http://localhost:1314/docs/Clippings/LLM/FinTextSim-Enhancing-Financial-Text-Analysis-with-BERTopic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/LLM/FinTextSim-Enhancing-Financial-Text-Analysis-with-BERTopic/</guid><description>&lt;p>arXiv:2504.15683v1 [cs.CL] 22 Apr 2025&lt;/p>
&lt;p>Simon Jehnen Javier Villalba-Díez Joaquín Ordieres-Meré&lt;/p>
&lt;h6 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h6>
&lt;p>Recent advancements in information availability and computational capabilities have transformed the analysis of annual reports, integrating traditional financial metrics with insights from textual data. To extract valuable insights from this wealth of textual data, automated review processes, such as topic modeling, are crucial. This study examines the effectiveness of BERTopic, a state-of-the-art topic model relying on contextual embeddings, for analyzing Item 7 and Item 7A of 10-K filings from S&amp;amp;P 500 companies (2016–2022). Moreover, we introduce FinTextSim, a finetuned sentence-transformer model optimized for clustering and semantic search in financial contexts. Compared to all-MiniLM-L6-v2, the most widely used sentence-transformer, FinTextSim increases intratopic similarity by 81% and reduces intertopic similarity by 100%, significantly enhancing organizational clarity. We assess BERTopic’s performance using embeddings from both FinTextSim and all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and distinct economic topic clusters when paired with FinTextSim’s embeddings. Without FinTextSim, BERTopic struggles with misclassification and overlapping topics. Thus, FinTextSim is pivotal for advancing financial text analysis. FinTextSim’s enhanced contextual embeddings, tailored for the financial domain, elevate the quality of future research and financial information. This improved quality of financial information will enable stakeholders to gain a competitive advantage, streamlining resource allocation and decision-making processes. Moreover, the improved insights have the potential to leverage business valuation and stock price prediction models.&lt;/p></description></item><item><title>From "Hallucination" to "Suture": Insights from Language Philosophy to Enhance Large Language Models</title><link>http://localhost:1314/docs/Clippings/Psychoanalysis/From-Hallucination-to-Suture-Insights-from-Language-Philosophy-to-Enhance-Large-Language-Models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Psychoanalysis/From-Hallucination-to-Suture-Insights-from-Language-Philosophy-to-Enhance-Large-Language-Models/</guid><description>&lt;p>[Submitted on 18 Mar 2025]&lt;/p>
&lt;h2 id="titlefrom-hallucination-to-suture-insights-from-language-philosophy-to-enhance-large-language-models">
 Title:From &amp;ldquo;Hallucination&amp;rdquo; to &amp;ldquo;Suture&amp;rdquo;: Insights from Language Philosophy to Enhance Large Language Models
 &lt;a class="anchor" href="#titlefrom-hallucination-to-suture-insights-from-language-philosophy-to-enhance-large-language-models">#&lt;/a>
&lt;/h2>
&lt;p>Authors:&lt;/p>
&lt;p>
 &lt;a href="https://arxiv.org/pdf/2503.14392">View PDF&lt;/a> 
 &lt;a href="https://arxiv.org/html/2503.14392v1">HTML (experimental)&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Abstract:This paper explores hallucination phenomena in large language models (LLMs) through the lens of language philosophy and psychoanalysis. By incorporating Lacan&amp;rsquo;s concepts of the &amp;ldquo;chain of signifiers&amp;rdquo; and &amp;ldquo;suture points,&amp;rdquo; we propose the Anchor-RAG framework as a novel approach to mitigate hallucinations. In contrast to the predominant reliance on trial-and-error experiments, constant adjustments of mathematical formulas, or resource-intensive methods that emphasize quantity over quality, our approach returns to the fundamental principles of linguistics to analyze the root causes of hallucinations in LLMs. Drawing from robust theoretical foundations, we derive algorithms and models that are not only effective in reducing hallucinations but also enhance LLM performance and improve output quality. This paper seeks to establish a comprehensive theoretical framework for understanding hallucinations in LLMs and aims to challenge the prevalent &amp;ldquo;guess-and-test&amp;rdquo; approach and rat race mentality in the field. We aspire to pave the way for a new era of interpretable LLMs, offering deeper insights into the inner workings of language-based AI systems.&lt;/p></description></item><item><title>Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges</title><link>http://localhost:1314/docs/Clippings/Deep-Learning/Geometric-Deep-Learning-Grids-Groups-Graphs-Geodesics-and-Gauges/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Deep-Learning/Geometric-Deep-Learning-Grids-Groups-Graphs-Geodesics-and-Gauges/</guid><description>&lt;p>[Submitted on 27 Apr 2021 (
 &lt;a href="https://arxiv.org/abs/2104.13478v1">v1&lt;/a>), last revised 2 May 2021 (this version, v2)]&lt;/p>
&lt;h2 id="titlegeometric-deep-learning-grids-groups-graphs-geodesics-and-gauges">
 Title:Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges
 &lt;a class="anchor" href="#titlegeometric-deep-learning-grids-groups-graphs-geodesics-and-gauges">#&lt;/a>
&lt;/h2>
&lt;p>Authors:, , ,&lt;/p>
&lt;p>
 &lt;a href="https://arxiv.org/pdf/2104.13478">View PDF&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Abstract:The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach &amp;ndash; such as computer vision, playing Go, or protein folding &amp;ndash; are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation.&lt;br>
While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications.&lt;br>
Such a &amp;lsquo;geometric unification&amp;rsquo; endeavour, in the spirit of Felix Klein&amp;rsquo;s Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.&lt;/p></description></item><item><title>Structured like a language model: Analysing AI as an automated subject - Liam Magee, Vanicka Arora, Luke Munn, 2023</title><link>http://localhost:1314/docs/Clippings/Psychoanalysis/Structured-like-a-language-model-Analysing-AI-as-an-automated-subject-Liam-Magee-Vanicka-Arora-Luke-Munn-2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1314/docs/Clippings/Psychoanalysis/Structured-like-a-language-model-Analysing-AI-as-an-automated-subject-Liam-Magee-Vanicka-Arora-Luke-Munn-2023/</guid><description>&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;p>Drawing from the resources of psychoanalysis and critical media studies, in this article we develop an analysis of large language models (LLMs) as ‘automated subjects’. We argue the intentional fictional projection of subjectivity onto LLMs can yield an alternate frame through which artificial intelligence (AI) behaviour, including its productions of bias and harm, can be analysed. First, we introduce language models, discuss their significance and risks, and outline our case for interpreting model design and outputs with support from psychoanalytic concepts. We trace a brief history of language models, culminating with the releases, in 2022, of systems that realise ‘state-of-the-art’ natural language processing performance. We engage with one such system, OpenAI&amp;rsquo;s InstructGPT, as a case study, detailing the layers of its construction and conducting exploratory and semi-structured interviews with chatbots. These interviews probe the model&amp;rsquo;s moral imperatives to be ‘helpful’, ‘truthful’ and ‘harmless’ by design. The model acts, we argue, as the condensation of often competing social desires, articulated through the internet and harvested into training data, which must then be regulated and repressed. This foundational structure can however be redirected via prompting, so that the model comes to identify with, and transfer*,* its commitments to the immediate human subject before it. In turn, these automated productions of language can lead to the human subject &lt;em>projecting&lt;/em> agency upon the model, effecting occasionally further forms of countertransference. We conclude that critical media methods and psychoanalytic theory together offer a productive frame for grasping the powerful new capacities of AI-driven language systems.&lt;/p></description></item></channel></rss>