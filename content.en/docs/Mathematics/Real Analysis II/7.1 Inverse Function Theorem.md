---
title: 7.1 Inverse Function Theorem
weight: 1
---

# 7.1 Inverse Function Theorem (IFT)

Two lines of ideas:

**A**: CMP $⇒$ Inverse FT $⇒$ Applications in ODE  
**B**: IFT $⇒$ Implicit FT $⇒$ Local behavior, extreme problems  

### I. Inverse Function Theorem
##### 1. Linear Case

Consider a linear map, $y = f(x): \mathbb{R}^n \to \mathbb{R}^n$.
$$
x = (x_1, x_2, \dots, x_n)^T
$$
Given $y \in \mathbb{R}^n$, $f(x)$ is a linear system of equations:

$$\begin{aligned}
y_1 &= a_{11} x_1 + a_{12} x_2 + \dots + a_{1n} x_n \\\\
y_2 &= a_{21} x_1 + a_{22} x_2 + \dots + a_{2n} x_n \\\\
&\vdots \\\\
y_n &= a_{n1} x_1 + \dots + a_{nn} x_n
\end{aligned}$$


or 
$$
A_{n\times n}X_{n\times 1} = Y_{n\times 1}
$$

> [!assumption|*]
>  $$X \text{ has a unique solution} \Longleftrightarrow \det(A) \neq 0.$$

In this case, the solution is given by:
$$
X = A^{-1} Y
$$
Thus, the inverse function satisfies:
$$
f^{-1} \circ f = \text{Identity}
$$
**The inverse theorem for $y = f(x)$:**

$$
f(f^{-1}(y)) = A A^{-1} y = y
$$

---

##### Question: When can we solve a **nonlinear** system?

We consider a system of nonlinear equations:
$$
\begin{cases}
    f_1(x_1, x_2, \dots, x_n) = y_1 \\\\
    f_2(x_1, x_2, \dots, x_n) = y_2 \\\\
    \quad \vdots \\\\
    f_n(x_1, x_2, \dots, x_n) = y_n
\end{cases}
$$
or equivalently, 
$$
f(x) = y
$$
##### 2. The Inverse of a General Function

**Notation:**  
Let $y = f(x): A \subset \mathbb{R}^n \to \mathbb{R}^n$ be a **diffeomorphism**.

$$
y = (y_1, y_2, \dots, y_n)
$$

where

$$
y_i = f_i(x_1, x_2, \dots, x_n)
$$

The Jacobian determinant of $f$ at $x$ is:

$$
\det \left( \frac{\partial f_i}{\partial x_j} \right)
$$

> [!theorem|7.1.1]
>Let $y = f(x): A \subset \mathbb{R}^n \to \mathbb{R}^n$ be of class $C^1$. Suppose $x_0 \in A$ and $\det(Df(x_0)) \neq 0$. Then there exists a neighborhood $U$ of $x_0$ and a neighborhood $W$ of $y_0 = f(x_0)$ such that:
>
>1. $f: U \to W$ has an **inverse** $f^{-1}: W \to U$.
>2. $f^{-1}$ is of class $C^1$.
>3. $D(f^{-1}(y)) = (Df(x))^{-1}$ for all $y \in W$ at $y = f(x)$.

---

### Visualization:

- $y = f(x)$ maps from $U$ to $W$.
- $x = f^{-1}(y)$ gives the inverse mapping from $W$ back to $U$.
# Recall: Contraction Mapping Principle (CMP)

Let $\mathbb{X}$ be a **complete metric space** and let 

$$
\varphi: \mathbb{X} \to \mathbb{X}
$$ 

be a function satisfying a contraction condition for some constant $k$ with $0 < k < 1$:

$$
d(\varphi(x), \varphi(y)) \leq k \cdot d(x,y), \quad \forall x,y \in \mathbb{X}.
$$

Then, there exists a **unique fixed point** $X^*$ such that:

$$
\varphi(X^*) = X^*.
$$

---

## Proof of the Inverse Function Theorem (IFT)

### Step 1: Reductions

(a) **May assume** that the Jacobian matrix at $x_0$ is the identity:
$$
D f(x_0) = I.
$$
In fact, define the transformation:
$$
T = D f(x_0).
$$
Then, we can consider a new function:

$$
\tilde{f} = T^{-1} \circ f.
$$

Thus, 

$$
D(\tilde{f})(x_0) = I.
$$

(b) **Main assumption:**  

$$
x_0 = f^{-1}(y_0).
$$

To see this, define:

$$
h(x) = f(x) - f(x_0).
$$

Then,

$$
D h(x_0) = D f(x_0) - D f(x_0) = 0.
$$

If $h^{-1}$ exists, then $y = f(x)$ can be solved as:

$$
f(x) = h(x) + f(x_0) = y.
$$

Thus, the inverse function satisfies:

$$
x = x_0 - h^{-1}(y - f(x_0)).
$$

---

## Step 2: Existence of the Inverse Function

(a) **Setup:** By the reduction above, we assume:

$$
x_0 = 0, \quad y_0 = f(x_0) = 0, \quad D f(x_0) = I.
$$

**Need to show:**  
There exist neighborhoods $U$ and $W$ such that the mapping:

$$
y = f(x): U \to W
$$

has an **inverse function** in $W$, meaning:

$$
\forall y \in W, \quad \exists! x \in U \text{ such that } y = f(x).
$$

**Illustration:**  

A diagram representing $U$ mapping to $W$ via $f$, where $f$ is invertible.

---

### For a fixed $y \in \mathbb{R}^n$, define:

$$
g_x = g(y) = y + x - f(x).
$$

We need to show that **$g_x$ has a unique fixed point**.

(b) **Construction of neighborhoods $U$ and $W$**  

Let:

$$
g(x) = x - f(x).
$$

Then:

$$
D g(x) = I - D f(x).
$$

Since:

$$
D g(x_0) = I - I = 0,
$$

it follows that:

$$
D g(x) \text{ is close to zero}.
$$

Thus, choosing:

$$
\epsilon = \frac{1}{2n},
$$

there exists $\delta > 0$ such that:

$$
\|x - x_0\| < \delta \implies \|D g_x(x)\| \leq \frac{1}{2n}.
$$

Applying the **Contraction Mapping Principle** to $g_x$, we obtain:

$$
\exists x \in B_{\delta}(x_0) \text{ such that } g_x(x) = x.
$$

Thus:

$$
g_x(x) = g_x(x_0) + D g_x(\xi)(x - x_0),
$$

which shows:

$$
D g_x(\xi) (x - x_0).
$$

---
# Chapter 7: Inverse and Implicit Function Theorems

## Contraction Mapping Principle (CMP)  
Let $\mathbb{X}$ be a **complete metric space**, and let $\varphi: \mathbb{X} \to \mathbb{X}$ satisfy:  

$$
d(\varphi(x), \varphi(y)) \leq k \cdot d(x,y), \quad 0 < k < 1.
$$  

Then, there exists a **unique fixed point** $X^*$ such that $\varphi(X^*) = X^*$.

---

## Proof of the Inverse Function Theorem (IFT)  

### Step 1: Reduction  
Assume $Df(x_0) = I$. Define $\tilde{f} = Df(x_0)^{-1} \circ f$, ensuring $D\tilde{f}(x_0) = I$.  
For $x_0 = f^{-1}(y_0)$, define $h(x) = f(x) - f(x_0)$. Since $Dh(x_0) = 0$, solving $f(x) = y$ reduces to:  

$$
x = x_0 - h^{-1}(y - f(x_0)).
$$  

---

### Step 2: Existence of the Inverse**  
Set up: $x_0 = 0, y_0 = f(x_0) = 0, Df(x_0) = I$. Need to show a local inverse:  

$$
\forall y \in W, \quad \exists! x \in U \text{ such that } y = f(x).
$$  

Define:  

$$
g_x(y) = y + x - f(x).
$$  

We need to show $g_x$ has a **unique fixed point**.  

Let $g(x) = x - f(x)$, then $Dg(x) = I - Df(x)$. Since $Dg(x_0) = 0$, choosing $\epsilon = \frac{1}{2n}$ ensures $\|D g_x(x)\|$ is small. Applying **CMP**, we get:  

$$
\exists x \in B_{\delta}(x_0) \text{ such that } g_x(x) = x.
$$
Thus, the inverse exists and is unique.  

